{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import gc\\nimport numpy as np\\nimport pandas as pd\\nimport xgboost as xgb\\nfrom sklearn.cross_validation import StratifiedKFold\\nfrom sklearn.metrics import matthews_corrcoef\\nfrom operator import itemgetter\\n\\n# per raddar, all date features except for stations 24+25 are identical\\n\\ndef get_date_features():\\n    directory = \\'../input/\\'\\n    trainfile = \\'train_date.csv\\'\\n    \\n    for i, chunk in enumerate(pd.read_csv(directory + trainfile,\\n                                          chunksize=1,\\n                                          low_memory=False)):\\n        features = list(chunk.columns)\\n        break\\n\\n    seen = np.zeros(52)\\n    rv = []\\n    for f in features:\\n        if f == \\'Id\\' or \\'S24\\' in f or \\'S25\\' in f:\\n            rv.append(f)\\n            continue\\n            \\n        station = int(f.split(\\'_\\')[1][1:])\\n#        print(station)\\n        \\n        if seen[station]:\\n            continue\\n        \\n        seen[station] = 1\\n        rv.append(f)\\n        \\n    return rv\\n        \\nusefuldatefeatures = get_date_features()\\n\\ndef get_mindate():\\n    directory = \\'../input/\\'\\n    trainfile = \\'train_date.csv\\'\\n    testfile = \\'test_date.csv\\'\\n    \\n    features = None\\n    subset = None\\n    \\n    for i, chunk in enumerate(pd.read_csv(directory + trainfile,\\n                                          usecols=usefuldatefeatures,\\n                                          chunksize=50000,\\n                                          low_memory=False)):\\n        print(i)\\n        \\n        if features is None:\\n            features = list(chunk.columns)\\n            features.remove(\\'Id\\')\\n        \\n        df_mindate_chunk = chunk[[\\'Id\\']].copy()\\n        df_mindate_chunk[\\'mindate\\'] = chunk[features].min(axis=1).values\\n        \\n        if subset is None:\\n            subset = df_mindate_chunk.copy()\\n        else:\\n            subset = pd.concat([subset, df_mindate_chunk])\\n            \\n        del chunk\\n        gc.collect()\\n\\n    for i, chunk in enumerate(pd.read_csv(directory + testfile,\\n                                          usecols=usefuldatefeatures,\\n                                          chunksize=50000,\\n                                          low_memory=False)):\\n        print(i)\\n        \\n        df_mindate_chunk = chunk[[\\'Id\\']].copy()\\n        df_mindate_chunk[\\'mindate\\'] = chunk[features].min(axis=1).values\\n        subset = pd.concat([subset, df_mindate_chunk])\\n        \\n        del chunk\\n        gc.collect()      \\n        \\n    return subset\\n\\n\\ndf_mindate = get_mindate()\\n\\ndf_mindate.sort_values(by=[\\'mindate\\', \\'Id\\'], inplace=True)\\n\\ndf_mindate[\\'mindate_id_diff\\'] = df_mindate.Id.diff()\\n\\nmidr = np.full_like(df_mindate.mindate_id_diff.values, np.nan)\\nmidr[0:-1] = -df_mindate.mindate_id_diff.values[1:]\\n\\ndf_mindate[\\'mindate_id_diff_reverse\\'] = midr\\n\\ndef mcc(tp, tn, fp, fn):\\n    sup = tp * tn - fp * fn\\n    inf = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\\n    if inf == 0:\\n        return 0\\n    else:\\n        return sup / np.sqrt(inf)\\n\\n\\ndef eval_mcc(y_true, y_prob, show=False):\\n    idx = np.argsort(y_prob)\\n    y_true_sort = y_true[idx]\\n    n = y_true.shape[0]\\n    nump = 1.0 * np.sum(y_true)  # number of positive\\n    numn = n - nump  # number of negative\\n    tp = nump\\n    tn = 0.0\\n    fp = numn\\n    fn = 0.0\\n    best_mcc = 0.0\\n    best_id = -1\\n    mccs = np.zeros(n)\\n    for i in range(n):\\n        if y_true_sort[i] == 1:\\n            tp -= 1.0\\n            fn += 1.0\\n        else:\\n            fp -= 1.0\\n            tn += 1.0\\n        new_mcc = mcc(tp, tn, fp, fn)\\n        mccs[i] = new_mcc\\n        if new_mcc >= best_mcc:\\n            best_mcc = new_mcc\\n            best_id = i\\n    if show:\\n        best_proba = y_prob[idx[best_id]]\\n        y_pred = (y_prob > best_proba).astype(int)\\n        return best_proba, best_mcc, y_pred\\n    else:\\n        return best_mcc\\n\\n\\ndef mcc_eval(y_prob, dtrain):\\n    y_true = dtrain.get_label()\\n    best_mcc = eval_mcc(y_true, y_prob)\\n    return \\'MCC\\', best_mcc\\n\\n\\ndef create_feature_map(features):\\n    outfile = open(\\'xgb.fmap\\', \\'w\\')\\n    for i, feat in enumerate(features):\\n        outfile.write(\\'{0}\\t{1}\\tq\\n\\'.format(i, feat))\\n    outfile.close()\\n\\n\\ndef get_importance(gbm, features):\\n    create_feature_map(features)\\n    importance = gbm.get_fscore(fmap=\\'xgb.fmap\\')\\n    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\\n    return importance\\n\\n\\ndef LeaveOneOut(data1, data2, columnName, useLOO=False):\\n    grpOutcomes = data1.groupby(columnName)[\\'Response\\'].mean().reset_index()\\n    grpCount = data1.groupby(columnName)[\\'Response\\'].count().reset_index()\\n    grpOutcomes[\\'cnt\\'] = grpCount.Response\\n    if(useLOO):\\n        grpOutcomes = grpOutcomes[grpOutcomes.cnt > 1]\\n    grpOutcomes.drop(\\'cnt\\', inplace=True, axis=1)\\n    outcomes = data2[\\'Response\\'].values\\n    x = pd.merge(data2[[columnName, \\'Response\\']], grpOutcomes,\\n                 suffixes=(\\'x_\\', \\'\\'),\\n                 how=\\'left\\',\\n                 on=columnName,\\n                 left_index=True)[\\'Response\\']\\n    if(useLOO):\\n        x = ((x*x.shape[0])-outcomes)/(x.shape[0]-1)\\n        #  x = x + np.random.normal(0, .01, x.shape[0])\\n    return x.fillna(x.mean())\\n\\n\\ndef GrabData():\\n    directory = \\'../input/\\'\\n    trainfiles = [\\'train_categorical.csv\\',\\n                  \\'train_date.csv\\',\\n                  \\'train_numeric.csv\\']\\n    testfiles = [\\'test_categorical.csv\\',\\n                 \\'test_date.csv\\',\\n                 \\'test_numeric.csv\\']\\n\\n    cols = [[\\'Id\\',\\n             \\'L1_S24_F1559\\', \\'L3_S32_F3851\\',\\n             \\'L1_S24_F1827\\', \\'L1_S24_F1582\\',\\n             \\'L3_S32_F3854\\', \\'L1_S24_F1510\\',\\n             \\'L1_S24_F1525\\'],\\n            [\\'Id\\',\\n             \\'L3_S30_D3496\\', \\'L3_S30_D3506\\',\\n             \\'L3_S30_D3501\\', \\'L3_S30_D3516\\',\\n             \\'L3_S30_D3511\\'],\\n            [\\'Id\\',\\n             \\'L1_S24_F1846\\', \\'L3_S32_F3850\\',\\n             \\'L1_S24_F1695\\', \\'L1_S24_F1632\\',\\n             \\'L3_S33_F3855\\', \\'L1_S24_F1604\\',\\n             \\'L3_S29_F3407\\', \\'L3_S33_F3865\\',\\n             \\'L3_S38_F3952\\', \\'L1_S24_F1723\\',\\n             \\'Response\\']]\\n    traindata = None\\n    testdata = None\\n    for i, f in enumerate(trainfiles):\\n        print(f)\\n        subset = None\\n        for i, chunk in enumerate(pd.read_csv(directory + f,\\n                                              usecols=cols[i],\\n                                              chunksize=50000,\\n                                              low_memory=False)):\\n            print(i)\\n            if subset is None:\\n                subset = chunk.copy()\\n            else:\\n                subset = pd.concat([subset, chunk])\\n            del chunk\\n            gc.collect()\\n        if traindata is None:\\n            traindata = subset.copy()\\n        else:\\n            traindata = pd.merge(traindata, subset.copy(), on=\"Id\")\\n        del subset\\n        gc.collect()\\n    del cols[2][-1]  # Test doesn\\'t have response!\\n    for i, f in enumerate(testfiles):\\n        print(f)\\n        subset = None\\n        for i, chunk in enumerate(pd.read_csv(directory + f,\\n                                              usecols=cols[i],\\n                                              chunksize=50000,\\n                                              low_memory=False)):\\n            print(i)\\n            if subset is None:\\n                subset = chunk.copy()\\n            else:\\n                subset = pd.concat([subset, chunk])\\n            del chunk\\n            gc.collect()\\n        if testdata is None:\\n            testdata = subset.copy()\\n        else:\\n            testdata = pd.merge(testdata, subset.copy(), on=\"Id\")\\n        del subset\\n        gc.collect()\\n        \\n    traindata = traindata.merge(df_mindate, on=\\'Id\\')\\n    testdata = testdata.merge(df_mindate, on=\\'Id\\')\\n        \\n    testdata[\\'Response\\'] = 0  # Add Dummy Value\\n    visibletraindata = traindata[::2]\\n    blindtraindata = traindata[1::2]\\n    print(blindtraindata.columns)\\n    for i in range(2):\\n        for col in cols[i][1:]:\\n            print(col)\\n            blindtraindata.loc[:, col] = LeaveOneOut(visibletraindata,\\n                                                     blindtraindata,\\n                                                     col, False).values\\n            testdata.loc[:, col] = LeaveOneOut(visibletraindata,\\n                                               testdata, col, False).values\\n    del visibletraindata\\n    gc.collect()\\n    testdata.drop(\\'Response\\', inplace=True, axis=1)\\n    return blindtraindata, testdata\\n\\n\\ndef Train():\\n    train, test = GrabData()\\n    print(\\'Train:\\', train.shape)\\n    print(\\'Test\\', test.shape)\\n    features = list(train.columns)\\n    features.remove(\\'Response\\')\\n    features.remove(\\'Id\\')\\n    print(features)\\n    num_rounds = 50\\n    params = {}\\n    params[\\'objective\\'] = \"binary:logistic\"\\n    params[\\'eta\\'] = 0.021\\n    params[\\'max_depth\\'] = 7\\n    params[\\'colsample_bytree\\'] = 0.82\\n    params[\\'min_child_weight\\'] = 3\\n    params[\\'base_score\\'] = 0.005\\n    params[\\'silent\\'] = True\\n\\n    print(\\'Fitting\\')\\n    trainpredictions = None\\n    testpredictions = None\\n\\n    dvisibletrain =         xgb.DMatrix(train[features],\\n                    train.Response,\\n                    silent=True)\\n    dtest =         xgb.DMatrix(test[features],\\n                    silent=True)\\n\\n    folds = 1\\n    for i in range(folds):\\n        print(\\'Fold:\\', i)\\n        params[\\'seed\\'] = i\\n        watchlist = [(dvisibletrain, \\'train\\'), (dvisibletrain, \\'val\\')]\\n        clf = xgb.train(params, dvisibletrain,\\n                        num_boost_round=num_rounds,\\n                        evals=watchlist,\\n                        early_stopping_rounds=20,\\n                        feval=mcc_eval,\\n                        maximize=True\\n                        )\\n        limit = clf.best_iteration+1\\n        # limit = clf.best_ntree_limit\\n        predictions =             clf.predict(dvisibletrain, ntree_limit=limit)\\n\\n        best_proba, best_mcc, y_pred = eval_mcc(train.Response,\\n                                                predictions,\\n                                                True)\\n        print(\\'tree limit:\\', limit)\\n        print(\\'mcc:\\', best_mcc)\\n        print(matthews_corrcoef(train.Response,\\n                                y_pred))\\n        if(trainpredictions is None):\\n            trainpredictions = predictions\\n        else:\\n            trainpredictions += predictions\\n        predictions = clf.predict(dtest, ntree_limit=limit)\\n        if(testpredictions is None):\\n            testpredictions = predictions\\n        else:\\n            testpredictions += predictions\\n        imp = get_importance(clf, features)\\n        print(\\'Importance array: \\', imp)\\n\\n    best_proba, best_mcc, y_pred = eval_mcc(train.Response,\\n                                            trainpredictions/folds,\\n                                            True)\\n    print(matthews_corrcoef(train.Response,\\n                            y_pred))\\n\\n    submission = pd.DataFrame({\"Id\": train.Id,\\n                               \"Prediction\": trainpredictions/folds,\\n                               \"Response\": train.Response})\\n    submission[[\\'Id\\',\\n                \\'Prediction\\',\\n                \\'Response\\']].to_csv(\\'rawtrainxgbsubmission\\'+str(folds)+\\'.csv\\',\\n                                    index=False)\\n\\n    submission = pd.DataFrame({\"Id\": test.Id.values,\\n                               \"Response\": testpredictions/folds})\\n    submission[[\\'Id\\', \\'Response\\']].to_csv(\\'rawxgbsubmission\\'+str(folds)+\\'.csv\\',\\n                                          index=False)\\n    y_pred = (testpredictions/folds > .08).astype(int)\\n    submission = pd.DataFrame({\"Id\": test.Id.values,\\n                               \"Response\": y_pred})\\n    submission[[\\'Id\\', \\'Response\\']].to_csv(\\'xgbsubmission\\'+str(folds)+\\'.csv\\',\\n                                          index=False)\\n\\nif __name__ == \"__main__\":\\n    print(\\'Started\\')\\n    Train()\\n    print(\\'Finished\\')\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from operator import itemgetter\n",
    "\n",
    "def get_date_features():\n",
    "    directory = '../input/'\n",
    "    trainfile = 'train_date.csv'\n",
    "    \n",
    "    for i, chunk in enumerate(pd.read_csv(directory + trainfile,\n",
    "                                          chunksize=1,\n",
    "                                          low_memory=False)):\n",
    "        features = list(chunk.columns)\n",
    "        break\n",
    "\n",
    "    seen = np.zeros(52)\n",
    "    rv = []\n",
    "    for f in features:\n",
    "        if f == 'Id' or 'S24' in f or 'S25' in f:\n",
    "            rv.append(f)\n",
    "            continue\n",
    "            \n",
    "        station = int(f.split('_')[1][1:])\n",
    "#        print(station)\n",
    "        \n",
    "        if seen[station]:\n",
    "            continue\n",
    "        \n",
    "        seen[station] = 1\n",
    "        rv.append(f)\n",
    "        \n",
    "    return rv\n",
    "        \n",
    "usefuldatefeatures = get_date_features()\n",
    "\n",
    "def get_mindate():\n",
    "    directory = '../input/'\n",
    "    trainfile = 'train_date.csv'\n",
    "    testfile = 'test_date.csv'\n",
    "    \n",
    "    features = None\n",
    "    subset = None\n",
    "    \n",
    "    for i, chunk in enumerate(pd.read_csv(directory + trainfile,\n",
    "                                          usecols=usefuldatefeatures,\n",
    "                                          chunksize=50000,\n",
    "                                          low_memory=False)):\n",
    "        print(i)\n",
    "        \n",
    "        if features is None:\n",
    "            features = list(chunk.columns)\n",
    "            features.remove('Id')\n",
    "        \n",
    "        df_mindate_chunk = chunk[['Id']].copy()\n",
    "        df_mindate_chunk['mindate'] = chunk[features].min(axis=1).values\n",
    "        \n",
    "        if subset is None:\n",
    "            subset = df_mindate_chunk.copy()\n",
    "        else:\n",
    "            subset = pd.concat([subset, df_mindate_chunk])\n",
    "            \n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "    for i, chunk in enumerate(pd.read_csv(directory + testfile,\n",
    "                                          usecols=usefuldatefeatures,\n",
    "                                          chunksize=50000,\n",
    "                                          low_memory=False)):\n",
    "        print(i)\n",
    "        \n",
    "        df_mindate_chunk = chunk[['Id']].copy()\n",
    "        df_mindate_chunk['mindate'] = chunk[features].min(axis=1).values\n",
    "        subset = pd.concat([subset, df_mindate_chunk])\n",
    "        \n",
    "        del chunk\n",
    "        gc.collect()      \n",
    "        \n",
    "    return subset\n",
    "\n",
    "\n",
    "df_mindate = get_mindate()\n",
    "\n",
    "df_mindate.sort_values(by=['mindate', 'Id'], inplace=True)\n",
    "\n",
    "df_mindate['mindate_id_diff'] = df_mindate.Id.diff()\n",
    "\n",
    "midr = np.full_like(df_mindate.mindate_id_diff.values, np.nan)\n",
    "midr[0:-1] = -df_mindate.mindate_id_diff.values[1:]\n",
    "\n",
    "df_mindate['mindate_id_diff_reverse'] = midr\n",
    "\n",
    "def mcc(tp, tn, fp, fn):\n",
    "    sup = tp * tn - fp * fn\n",
    "    inf = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    if inf == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sup / np.sqrt(inf)\n",
    "\n",
    "\n",
    "def eval_mcc(y_true, y_prob, show=False):\n",
    "    idx = np.argsort(y_prob)\n",
    "    y_true_sort = y_true[idx]\n",
    "    n = y_true.shape[0]\n",
    "    nump = 1.0 * np.sum(y_true)  # number of positive\n",
    "    numn = n - nump  # number of negative\n",
    "    tp = nump\n",
    "    tn = 0.0\n",
    "    fp = numn\n",
    "    fn = 0.0\n",
    "    best_mcc = 0.0\n",
    "    best_id = -1\n",
    "    mccs = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if y_true_sort[i] == 1:\n",
    "            tp -= 1.0\n",
    "            fn += 1.0\n",
    "        else:\n",
    "            fp -= 1.0\n",
    "            tn += 1.0\n",
    "        new_mcc = mcc(tp, tn, fp, fn)\n",
    "        mccs[i] = new_mcc\n",
    "        if new_mcc >= best_mcc:\n",
    "            best_mcc = new_mcc\n",
    "            best_id = i\n",
    "    if show:\n",
    "        best_proba = y_prob[idx[best_id]]\n",
    "        y_pred = (y_prob > best_proba).astype(int)\n",
    "        return best_proba, best_mcc, y_pred\n",
    "    else:\n",
    "        return best_mcc\n",
    "\n",
    "\n",
    "def mcc_eval(y_prob, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    best_mcc = eval_mcc(y_true, y_prob)\n",
    "    return 'MCC', best_mcc\n",
    "\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n",
    "\n",
    "\n",
    "def LeaveOneOut(data1, data2, columnName, useLOO=False):\n",
    "    grpOutcomes = data1.groupby(columnName)['Response'].mean().reset_index()\n",
    "    grpCount = data1.groupby(columnName)['Response'].count().reset_index()\n",
    "    grpOutcomes['cnt'] = grpCount.Response\n",
    "    if(useLOO):\n",
    "        grpOutcomes = grpOutcomes[grpOutcomes.cnt > 1]\n",
    "    grpOutcomes.drop('cnt', inplace=True, axis=1)\n",
    "    outcomes = data2['Response'].values\n",
    "    x = pd.merge(data2[[columnName, 'Response']], grpOutcomes,\n",
    "                 suffixes=('x_', ''),\n",
    "                 how='left',\n",
    "                 on=columnName,\n",
    "                 left_index=True)['Response']\n",
    "    if(useLOO):\n",
    "        x = ((x*x.shape[0])-outcomes)/(x.shape[0]-1)\n",
    "        #  x = x + np.random.normal(0, .01, x.shape[0])\n",
    "    return x.fillna(x.mean())\n",
    "\n",
    "\n",
    "def GrabData():\n",
    "    directory = '../input/'\n",
    "    trainfiles = ['train_categorical.csv',\n",
    "                  'train_date.csv',\n",
    "                  'train_numeric.csv']\n",
    "    testfiles = ['test_categorical.csv',\n",
    "                 'test_date.csv',\n",
    "                 'test_numeric.csv']\n",
    "\n",
    "    cols = [['Id',\n",
    "             'L1_S24_F1559', 'L3_S32_F3851',\n",
    "             'L1_S24_F1827', 'L1_S24_F1582',\n",
    "             'L3_S32_F3854', 'L1_S24_F1510',\n",
    "             'L1_S24_F1525'],\n",
    "            ['Id',\n",
    "             'L3_S30_D3496', 'L3_S30_D3506',\n",
    "             'L3_S30_D3501', 'L3_S30_D3516',\n",
    "             'L3_S30_D3511'],\n",
    "            ['Id',\n",
    "             'L1_S24_F1846', 'L3_S32_F3850',\n",
    "             'L1_S24_F1695', 'L1_S24_F1632',\n",
    "             'L3_S33_F3855', 'L1_S24_F1604',\n",
    "             'L3_S29_F3407', 'L3_S33_F3865',\n",
    "             'L3_S38_F3952', 'L1_S24_F1723',\n",
    "             'Response']]\n",
    "    traindata = None\n",
    "    testdata = None\n",
    "    for i, f in enumerate(trainfiles):\n",
    "        print(f)\n",
    "        subset = None\n",
    "        for i, chunk in enumerate(pd.read_csv(directory + f,\n",
    "                                              usecols=cols[i],\n",
    "                                              chunksize=50000,\n",
    "                                              low_memory=False)):\n",
    "            print(i)\n",
    "            if subset is None:\n",
    "                subset = chunk.copy()\n",
    "            else:\n",
    "                subset = pd.concat([subset, chunk])\n",
    "            del chunk\n",
    "            gc.collect()\n",
    "        if traindata is None:\n",
    "            traindata = subset.copy()\n",
    "        else:\n",
    "            traindata = pd.merge(traindata, subset.copy(), on=\"Id\")\n",
    "        del subset\n",
    "        gc.collect()\n",
    "    del cols[2][-1]  # Test doesn't have response!\n",
    "    for i, f in enumerate(testfiles):\n",
    "        print(f)\n",
    "        subset = None\n",
    "        for i, chunk in enumerate(pd.read_csv(directory + f,\n",
    "                                              usecols=cols[i],\n",
    "                                              chunksize=50000,\n",
    "                                              low_memory=False)):\n",
    "            print(i)\n",
    "            if subset is None:\n",
    "                subset = chunk.copy()\n",
    "            else:\n",
    "                subset = pd.concat([subset, chunk])\n",
    "            del chunk\n",
    "            gc.collect()\n",
    "        if testdata is None:\n",
    "            testdata = subset.copy()\n",
    "        else:\n",
    "            testdata = pd.merge(testdata, subset.copy(), on=\"Id\")\n",
    "        del subset\n",
    "        gc.collect()\n",
    "        \n",
    "    traindata = traindata.merge(df_mindate, on='Id')\n",
    "    testdata = testdata.merge(df_mindate, on='Id')\n",
    "        \n",
    "    testdata['Response'] = 0  # Add Dummy Value\n",
    "    visibletraindata = traindata[::2]\n",
    "    blindtraindata = traindata[1::2]\n",
    "    print(blindtraindata.columns)\n",
    "    for i in range(2):\n",
    "        for col in cols[i][1:]:\n",
    "            print(col)\n",
    "            blindtraindata.loc[:, col] = LeaveOneOut(visibletraindata,\n",
    "                                                     blindtraindata,\n",
    "                                                     col, False).values\n",
    "            testdata.loc[:, col] = LeaveOneOut(visibletraindata,\n",
    "                                               testdata, col, False).values\n",
    "    del visibletraindata\n",
    "    gc.collect()\n",
    "    testdata.drop('Response', inplace=True, axis=1)\n",
    "    return blindtraindata, testdata\n",
    "\n",
    "\n",
    "def Train():\n",
    "    train, test = GrabData()\n",
    "    print('Train:', train.shape)\n",
    "    print('Test', test.shape)\n",
    "    features = list(train.columns)\n",
    "    features.remove('Response')\n",
    "    features.remove('Id')\n",
    "    print(features)\n",
    "    num_rounds = 50\n",
    "    params = {}\n",
    "    params['objective'] = \"binary:logistic\"\n",
    "    params['eta'] = 0.021\n",
    "    params['max_depth'] = 7\n",
    "    params['colsample_bytree'] = 0.82\n",
    "    params['min_child_weight'] = 3\n",
    "    params['base_score'] = 0.005\n",
    "    params['silent'] = True\n",
    "\n",
    "    print('Fitting')\n",
    "    trainpredictions = None\n",
    "    testpredictions = None\n",
    "\n",
    "    dvisibletrain = \\\n",
    "        xgb.DMatrix(train[features],\n",
    "                    train.Response,\n",
    "                    silent=True)\n",
    "    dtest = \\\n",
    "        xgb.DMatrix(test[features],\n",
    "                    silent=True)\n",
    "\n",
    "    folds = 1\n",
    "    for i in range(folds):\n",
    "        print('Fold:', i)\n",
    "        params['seed'] = i\n",
    "        watchlist = [(dvisibletrain, 'train'), (dvisibletrain, 'val')]\n",
    "        clf = xgb.train(params, dvisibletrain,\n",
    "                        num_boost_round=num_rounds,\n",
    "                        evals=watchlist,\n",
    "                        early_stopping_rounds=20,\n",
    "                        feval=mcc_eval,\n",
    "                        maximize=True\n",
    "                        )\n",
    "        limit = clf.best_iteration+1\n",
    "        # limit = clf.best_ntree_limit\n",
    "        predictions = \\\n",
    "            clf.predict(dvisibletrain, ntree_limit=limit)\n",
    "\n",
    "        best_proba, best_mcc, y_pred = eval_mcc(train.Response,\n",
    "                                                predictions,\n",
    "                                                True)\n",
    "        print('tree limit:', limit)\n",
    "        print('mcc:', best_mcc)\n",
    "        print(matthews_corrcoef(train.Response,\n",
    "                                y_pred))\n",
    "        if(trainpredictions is None):\n",
    "            trainpredictions = predictions\n",
    "        else:\n",
    "            trainpredictions += predictions\n",
    "        predictions = clf.predict(dtest, ntree_limit=limit)\n",
    "        if(testpredictions is None):\n",
    "            testpredictions = predictions\n",
    "        else:\n",
    "            testpredictions += predictions\n",
    "        imp = get_importance(clf, features)\n",
    "        print('Importance array: ', imp)\n",
    "\n",
    "    best_proba, best_mcc, y_pred = eval_mcc(train.Response,\n",
    "                                            trainpredictions/folds,\n",
    "                                            True)\n",
    "    print(matthews_corrcoef(train.Response,\n",
    "                            y_pred))\n",
    "\n",
    "    submission = pd.DataFrame({\"Id\": train.Id,\n",
    "                               \"Prediction\": trainpredictions/folds,\n",
    "                               \"Response\": train.Response})\n",
    "    submission[['Id',\n",
    "                'Prediction',\n",
    "                'Response']].to_csv('rawtrainxgbsubmission'+str(folds)+'.csv',\n",
    "                                    index=False)\n",
    "\n",
    "    submission = pd.DataFrame({\"Id\": test.Id.values,\n",
    "                               \"Response\": testpredictions/folds})\n",
    "    submission[['Id', 'Response']].to_csv('rawxgbsubmission'+str(folds)+'.csv',\n",
    "                                          index=False)\n",
    "    y_pred = (testpredictions/folds > .08).astype(int)\n",
    "    submission = pd.DataFrame({\"Id\": test.Id.values,\n",
    "                               \"Response\": y_pred})\n",
    "    submission[['Id', 'Response']].to_csv('xgbsubmission'+str(folds)+'.csv',\n",
    "                                          index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Started')\n",
    "    Train()\n",
    "    print('Finished')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "38\n",
      "38\n",
      "38\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "40\n",
      "40\n",
      "40\n",
      "40\n",
      "40\n",
      "40\n",
      "40\n",
      "40\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "46\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "51\n",
      "51\n",
      "51\n",
      "51\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from operator import itemgetter\n",
    "\n",
    "def get_date_features():\n",
    "    directory = '../data/'\n",
    "    trainfile = 'train_date.csv'\n",
    "    \n",
    "    for i, chunk in enumerate(pd.read_csv(directory + trainfile,\n",
    "                                          chunksize=1,\n",
    "                                          low_memory=False)):\n",
    "        features = list(chunk.columns)\n",
    "        break\n",
    "\n",
    "    seen = np.zeros(52)\n",
    "    rv = []\n",
    "    for f in features:\n",
    "        if f == 'Id' or 'S24' in f or 'S25' in f:\n",
    "            rv.append(f)\n",
    "            continue\n",
    "            \n",
    "        station = int(f.split('_')[1][1:])\n",
    "        print(station)\n",
    "        \n",
    "        if seen[station]:\n",
    "            continue\n",
    "        \n",
    "        seen[station] = 1\n",
    "        rv.append(f)\n",
    "        \n",
    "    return rv\n",
    "        \n",
    "usefuldatefeatures = get_date_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'L0_S0_D1',\n",
       " 'L0_S1_D26',\n",
       " 'L0_S2_D34',\n",
       " 'L0_S3_D70',\n",
       " 'L0_S4_D106',\n",
       " 'L0_S5_D115',\n",
       " 'L0_S6_D120',\n",
       " 'L0_S7_D137',\n",
       " 'L0_S8_D145',\n",
       " 'L0_S9_D152',\n",
       " 'L0_S10_D216',\n",
       " 'L0_S11_D280',\n",
       " 'L0_S12_D331',\n",
       " 'L0_S13_D355',\n",
       " 'L0_S14_D360',\n",
       " 'L0_S15_D395',\n",
       " 'L0_S16_D423',\n",
       " 'L0_S17_D432',\n",
       " 'L0_S18_D437',\n",
       " 'L0_S19_D454',\n",
       " 'L0_S20_D462',\n",
       " 'L0_S21_D469',\n",
       " 'L0_S22_D543',\n",
       " 'L0_S23_D617',\n",
       " 'L1_S24_D677',\n",
       " 'L1_S24_D681',\n",
       " 'L1_S24_D685',\n",
       " 'L1_S24_D689',\n",
       " 'L1_S24_D693',\n",
       " 'L1_S24_D697',\n",
       " 'L1_S24_D702',\n",
       " 'L1_S24_D707',\n",
       " 'L1_S24_D712',\n",
       " 'L1_S24_D716',\n",
       " 'L1_S24_D721',\n",
       " 'L1_S24_D725',\n",
       " 'L1_S24_D730',\n",
       " 'L1_S24_D735',\n",
       " 'L1_S24_D739',\n",
       " 'L1_S24_D743',\n",
       " 'L1_S24_D748',\n",
       " 'L1_S24_D753',\n",
       " 'L1_S24_D758',\n",
       " 'L1_S24_D763',\n",
       " 'L1_S24_D768',\n",
       " 'L1_S24_D772',\n",
       " 'L1_S24_D777',\n",
       " 'L1_S24_D782',\n",
       " 'L1_S24_D787',\n",
       " 'L1_S24_D792',\n",
       " 'L1_S24_D797',\n",
       " 'L1_S24_D801',\n",
       " 'L1_S24_D804',\n",
       " 'L1_S24_D807',\n",
       " 'L1_S24_D809',\n",
       " 'L1_S24_D811',\n",
       " 'L1_S24_D813',\n",
       " 'L1_S24_D815',\n",
       " 'L1_S24_D818',\n",
       " 'L1_S24_D822',\n",
       " 'L1_S24_D826',\n",
       " 'L1_S24_D831',\n",
       " 'L1_S24_D836',\n",
       " 'L1_S24_D841',\n",
       " 'L1_S24_D846',\n",
       " 'L1_S24_D850',\n",
       " 'L1_S24_D854',\n",
       " 'L1_S24_D859',\n",
       " 'L1_S24_D864',\n",
       " 'L1_S24_D869',\n",
       " 'L1_S24_D874',\n",
       " 'L1_S24_D879',\n",
       " 'L1_S24_D884',\n",
       " 'L1_S24_D889',\n",
       " 'L1_S24_D894',\n",
       " 'L1_S24_D899',\n",
       " 'L1_S24_D904',\n",
       " 'L1_S24_D909',\n",
       " 'L1_S24_D913',\n",
       " 'L1_S24_D917',\n",
       " 'L1_S24_D922',\n",
       " 'L1_S24_D927',\n",
       " 'L1_S24_D932',\n",
       " 'L1_S24_D937',\n",
       " 'L1_S24_D941',\n",
       " 'L1_S24_D945',\n",
       " 'L1_S24_D950',\n",
       " 'L1_S24_D955',\n",
       " 'L1_S24_D960',\n",
       " 'L1_S24_D965',\n",
       " 'L1_S24_D970',\n",
       " 'L1_S24_D975',\n",
       " 'L1_S24_D980',\n",
       " 'L1_S24_D985',\n",
       " 'L1_S24_D990',\n",
       " 'L1_S24_D995',\n",
       " 'L1_S24_D999',\n",
       " 'L1_S24_D1001',\n",
       " 'L1_S24_D1003',\n",
       " 'L1_S24_D1005',\n",
       " 'L1_S24_D1007',\n",
       " 'L1_S24_D1009',\n",
       " 'L1_S24_D1011',\n",
       " 'L1_S24_D1013',\n",
       " 'L1_S24_D1015',\n",
       " 'L1_S24_D1018',\n",
       " 'L1_S24_D1023',\n",
       " 'L1_S24_D1028',\n",
       " 'L1_S24_D1033',\n",
       " 'L1_S24_D1038',\n",
       " 'L1_S24_D1043',\n",
       " 'L1_S24_D1048',\n",
       " 'L1_S24_D1053',\n",
       " 'L1_S24_D1058',\n",
       " 'L1_S24_D1062',\n",
       " 'L1_S24_D1066',\n",
       " 'L1_S24_D1070',\n",
       " 'L1_S24_D1074',\n",
       " 'L1_S24_D1077',\n",
       " 'L1_S24_D1081',\n",
       " 'L1_S24_D1085',\n",
       " 'L1_S24_D1089',\n",
       " 'L1_S24_D1092',\n",
       " 'L1_S24_D1096',\n",
       " 'L1_S24_D1100',\n",
       " 'L1_S24_D1104',\n",
       " 'L1_S24_D1108',\n",
       " 'L1_S24_D1112',\n",
       " 'L1_S24_D1116',\n",
       " 'L1_S24_D1120',\n",
       " 'L1_S24_D1124',\n",
       " 'L1_S24_D1128',\n",
       " 'L1_S24_D1132',\n",
       " 'L1_S24_D1135',\n",
       " 'L1_S24_D1138',\n",
       " 'L1_S24_D1141',\n",
       " 'L1_S24_D1143',\n",
       " 'L1_S24_D1146',\n",
       " 'L1_S24_D1149',\n",
       " 'L1_S24_D1151',\n",
       " 'L1_S24_D1153',\n",
       " 'L1_S24_D1155',\n",
       " 'L1_S24_D1158',\n",
       " 'L1_S24_D1163',\n",
       " 'L1_S24_D1168',\n",
       " 'L1_S24_D1171',\n",
       " 'L1_S24_D1173',\n",
       " 'L1_S24_D1175',\n",
       " 'L1_S24_D1178',\n",
       " 'L1_S24_D1182',\n",
       " 'L1_S24_D1186',\n",
       " 'L1_S24_D1190',\n",
       " 'L1_S24_D1194',\n",
       " 'L1_S24_D1199',\n",
       " 'L1_S24_D1204',\n",
       " 'L1_S24_D1209',\n",
       " 'L1_S24_D1214',\n",
       " 'L1_S24_D1218',\n",
       " 'L1_S24_D1222',\n",
       " 'L1_S24_D1227',\n",
       " 'L1_S24_D1232',\n",
       " 'L1_S24_D1237',\n",
       " 'L1_S24_D1242',\n",
       " 'L1_S24_D1247',\n",
       " 'L1_S24_D1252',\n",
       " 'L1_S24_D1257',\n",
       " 'L1_S24_D1262',\n",
       " 'L1_S24_D1267',\n",
       " 'L1_S24_D1272',\n",
       " 'L1_S24_D1277',\n",
       " 'L1_S24_D1281',\n",
       " 'L1_S24_D1285',\n",
       " 'L1_S24_D1290',\n",
       " 'L1_S24_D1295',\n",
       " 'L1_S24_D1300',\n",
       " 'L1_S24_D1305',\n",
       " 'L1_S24_D1309',\n",
       " 'L1_S24_D1313',\n",
       " 'L1_S24_D1318',\n",
       " 'L1_S24_D1323',\n",
       " 'L1_S24_D1328',\n",
       " 'L1_S24_D1333',\n",
       " 'L1_S24_D1338',\n",
       " 'L1_S24_D1343',\n",
       " 'L1_S24_D1348',\n",
       " 'L1_S24_D1353',\n",
       " 'L1_S24_D1358',\n",
       " 'L1_S24_D1363',\n",
       " 'L1_S24_D1368',\n",
       " 'L1_S24_D1373',\n",
       " 'L1_S24_D1378',\n",
       " 'L1_S24_D1383',\n",
       " 'L1_S24_D1388',\n",
       " 'L1_S24_D1393',\n",
       " 'L1_S24_D1398',\n",
       " 'L1_S24_D1403',\n",
       " 'L1_S24_D1408',\n",
       " 'L1_S24_D1413',\n",
       " 'L1_S24_D1418',\n",
       " 'L1_S24_D1423',\n",
       " 'L1_S24_D1428',\n",
       " 'L1_S24_D1433',\n",
       " 'L1_S24_D1438',\n",
       " 'L1_S24_D1443',\n",
       " 'L1_S24_D1448',\n",
       " 'L1_S24_D1453',\n",
       " 'L1_S24_D1457',\n",
       " 'L1_S24_D1461',\n",
       " 'L1_S24_D1465',\n",
       " 'L1_S24_D1469',\n",
       " 'L1_S24_D1472',\n",
       " 'L1_S24_D1476',\n",
       " 'L1_S24_D1480',\n",
       " 'L1_S24_D1484',\n",
       " 'L1_S24_D1488',\n",
       " 'L1_S24_D1492',\n",
       " 'L1_S24_D1496',\n",
       " 'L1_S24_D1500',\n",
       " 'L1_S24_D1504',\n",
       " 'L1_S24_D1508',\n",
       " 'L1_S24_D1511',\n",
       " 'L1_S24_D1513',\n",
       " 'L1_S24_D1515',\n",
       " 'L1_S24_D1517',\n",
       " 'L1_S24_D1519',\n",
       " 'L1_S24_D1522',\n",
       " 'L1_S24_D1527',\n",
       " 'L1_S24_D1532',\n",
       " 'L1_S24_D1536',\n",
       " 'L1_S24_D1541',\n",
       " 'L1_S24_D1546',\n",
       " 'L1_S24_D1550',\n",
       " 'L1_S24_D1554',\n",
       " 'L1_S24_D1558',\n",
       " 'L1_S24_D1562',\n",
       " 'L1_S24_D1566',\n",
       " 'L1_S24_D1568',\n",
       " 'L1_S24_D1570',\n",
       " 'L1_S24_D1572',\n",
       " 'L1_S24_D1574',\n",
       " 'L1_S24_D1576',\n",
       " 'L1_S24_D1579',\n",
       " 'L1_S24_D1583',\n",
       " 'L1_S24_D1587',\n",
       " 'L1_S24_D1591',\n",
       " 'L1_S24_D1596',\n",
       " 'L1_S24_D1601',\n",
       " 'L1_S24_D1606',\n",
       " 'L1_S24_D1611',\n",
       " 'L1_S24_D1615',\n",
       " 'L1_S24_D1619',\n",
       " 'L1_S24_D1624',\n",
       " 'L1_S24_D1629',\n",
       " 'L1_S24_D1634',\n",
       " 'L1_S24_D1639',\n",
       " 'L1_S24_D1644',\n",
       " 'L1_S24_D1649',\n",
       " 'L1_S24_D1654',\n",
       " 'L1_S24_D1659',\n",
       " 'L1_S24_D1664',\n",
       " 'L1_S24_D1669',\n",
       " 'L1_S24_D1674',\n",
       " 'L1_S24_D1678',\n",
       " 'L1_S24_D1682',\n",
       " 'L1_S24_D1687',\n",
       " 'L1_S24_D1692',\n",
       " 'L1_S24_D1697',\n",
       " 'L1_S24_D1702',\n",
       " 'L1_S24_D1706',\n",
       " 'L1_S24_D1710',\n",
       " 'L1_S24_D1715',\n",
       " 'L1_S24_D1720',\n",
       " 'L1_S24_D1725',\n",
       " 'L1_S24_D1730',\n",
       " 'L1_S24_D1735',\n",
       " 'L1_S24_D1740',\n",
       " 'L1_S24_D1745',\n",
       " 'L1_S24_D1750',\n",
       " 'L1_S24_D1755',\n",
       " 'L1_S24_D1760',\n",
       " 'L1_S24_D1765',\n",
       " 'L1_S24_D1770',\n",
       " 'L1_S24_D1775',\n",
       " 'L1_S24_D1780',\n",
       " 'L1_S24_D1785',\n",
       " 'L1_S24_D1790',\n",
       " 'L1_S24_D1795',\n",
       " 'L1_S24_D1800',\n",
       " 'L1_S24_D1805',\n",
       " 'L1_S24_D1809',\n",
       " 'L1_S24_D1811',\n",
       " 'L1_S24_D1813',\n",
       " 'L1_S24_D1815',\n",
       " 'L1_S24_D1817',\n",
       " 'L1_S24_D1819',\n",
       " 'L1_S24_D1821',\n",
       " 'L1_S24_D1823',\n",
       " 'L1_S24_D1825',\n",
       " 'L1_S24_D1826',\n",
       " 'L1_S24_D1828',\n",
       " 'L1_S24_D1830',\n",
       " 'L1_S24_D1832',\n",
       " 'L1_S24_D1833',\n",
       " 'L1_S24_D1835',\n",
       " 'L1_S24_D1837',\n",
       " 'L1_S24_D1839',\n",
       " 'L1_S24_D1841',\n",
       " 'L1_S24_D1843',\n",
       " 'L1_S24_D1845',\n",
       " 'L1_S24_D1847',\n",
       " 'L1_S24_D1849',\n",
       " 'L1_S24_D1851',\n",
       " 'L1_S25_D1854',\n",
       " 'L1_S25_D1857',\n",
       " 'L1_S25_D1860',\n",
       " 'L1_S25_D1862',\n",
       " 'L1_S25_D1864',\n",
       " 'L1_S25_D1867',\n",
       " 'L1_S25_D1871',\n",
       " 'L1_S25_D1875',\n",
       " 'L1_S25_D1879',\n",
       " 'L1_S25_D1883',\n",
       " 'L1_S25_D1887',\n",
       " 'L1_S25_D1891',\n",
       " 'L1_S25_D1893',\n",
       " 'L1_S25_D1895',\n",
       " 'L1_S25_D1898',\n",
       " 'L1_S25_D1902',\n",
       " 'L1_S25_D1906',\n",
       " 'L1_S25_D1911',\n",
       " 'L1_S25_D1916',\n",
       " 'L1_S25_D1921',\n",
       " 'L1_S25_D1926',\n",
       " 'L1_S25_D1931',\n",
       " 'L1_S25_D1935',\n",
       " 'L1_S25_D1940',\n",
       " 'L1_S25_D1945',\n",
       " 'L1_S25_D1950',\n",
       " 'L1_S25_D1955',\n",
       " 'L1_S25_D1960',\n",
       " 'L1_S25_D1965',\n",
       " 'L1_S25_D1970',\n",
       " 'L1_S25_D1975',\n",
       " 'L1_S25_D1980',\n",
       " 'L1_S25_D1984',\n",
       " 'L1_S25_D1989',\n",
       " 'L1_S25_D1994',\n",
       " 'L1_S25_D1999',\n",
       " 'L1_S25_D2004',\n",
       " 'L1_S25_D2009',\n",
       " 'L1_S25_D2013',\n",
       " 'L1_S25_D2018',\n",
       " 'L1_S25_D2023',\n",
       " 'L1_S25_D2028',\n",
       " 'L1_S25_D2033',\n",
       " 'L1_S25_D2038',\n",
       " 'L1_S25_D2043',\n",
       " 'L1_S25_D2048',\n",
       " 'L1_S25_D2053',\n",
       " 'L1_S25_D2058',\n",
       " 'L1_S25_D2063',\n",
       " 'L1_S25_D2068',\n",
       " 'L1_S25_D2073',\n",
       " 'L1_S25_D2078',\n",
       " 'L1_S25_D2083',\n",
       " 'L1_S25_D2088',\n",
       " 'L1_S25_D2093',\n",
       " 'L1_S25_D2098',\n",
       " 'L1_S25_D2103',\n",
       " 'L1_S25_D2108',\n",
       " 'L1_S25_D2113',\n",
       " 'L1_S25_D2118',\n",
       " 'L1_S25_D2123',\n",
       " 'L1_S25_D2128',\n",
       " 'L1_S25_D2133',\n",
       " 'L1_S25_D2138',\n",
       " 'L1_S25_D2140',\n",
       " 'L1_S25_D2143',\n",
       " 'L1_S25_D2146',\n",
       " 'L1_S25_D2149',\n",
       " 'L1_S25_D2151',\n",
       " 'L1_S25_D2154',\n",
       " 'L1_S25_D2157',\n",
       " 'L1_S25_D2160',\n",
       " 'L1_S25_D2163',\n",
       " 'L1_S25_D2166',\n",
       " 'L1_S25_D2169',\n",
       " 'L1_S25_D2172',\n",
       " 'L1_S25_D2175',\n",
       " 'L1_S25_D2178',\n",
       " 'L1_S25_D2180',\n",
       " 'L1_S25_D2183',\n",
       " 'L1_S25_D2186',\n",
       " 'L1_S25_D2189',\n",
       " 'L1_S25_D2192',\n",
       " 'L1_S25_D2195',\n",
       " 'L1_S25_D2198',\n",
       " 'L1_S25_D2201',\n",
       " 'L1_S25_D2204',\n",
       " 'L1_S25_D2206',\n",
       " 'L1_S25_D2209',\n",
       " 'L1_S25_D2212',\n",
       " 'L1_S25_D2214',\n",
       " 'L1_S25_D2216',\n",
       " 'L1_S25_D2219',\n",
       " 'L1_S25_D2222',\n",
       " 'L1_S25_D2225',\n",
       " 'L1_S25_D2228',\n",
       " 'L1_S25_D2230',\n",
       " 'L1_S25_D2232',\n",
       " 'L1_S25_D2234',\n",
       " 'L1_S25_D2235',\n",
       " 'L1_S25_D2236',\n",
       " 'L1_S25_D2238',\n",
       " 'L1_S25_D2240',\n",
       " 'L1_S25_D2242',\n",
       " 'L1_S25_D2244',\n",
       " 'L1_S25_D2246',\n",
       " 'L1_S25_D2248',\n",
       " 'L1_S25_D2251',\n",
       " 'L1_S25_D2255',\n",
       " 'L1_S25_D2260',\n",
       " 'L1_S25_D2265',\n",
       " 'L1_S25_D2270',\n",
       " 'L1_S25_D2275',\n",
       " 'L1_S25_D2280',\n",
       " 'L1_S25_D2284',\n",
       " 'L1_S25_D2289',\n",
       " 'L1_S25_D2294',\n",
       " 'L1_S25_D2299',\n",
       " 'L1_S25_D2304',\n",
       " 'L1_S25_D2309',\n",
       " 'L1_S25_D2314',\n",
       " 'L1_S25_D2319',\n",
       " 'L1_S25_D2324',\n",
       " 'L1_S25_D2329',\n",
       " 'L1_S25_D2333',\n",
       " 'L1_S25_D2338',\n",
       " 'L1_S25_D2343',\n",
       " 'L1_S25_D2348',\n",
       " 'L1_S25_D2353',\n",
       " 'L1_S25_D2358',\n",
       " 'L1_S25_D2362',\n",
       " 'L1_S25_D2367',\n",
       " 'L1_S25_D2372',\n",
       " 'L1_S25_D2377',\n",
       " 'L1_S25_D2382',\n",
       " 'L1_S25_D2387',\n",
       " 'L1_S25_D2392',\n",
       " 'L1_S25_D2397',\n",
       " 'L1_S25_D2402',\n",
       " 'L1_S25_D2406',\n",
       " 'L1_S25_D2409',\n",
       " 'L1_S25_D2412',\n",
       " 'L1_S25_D2415',\n",
       " 'L1_S25_D2418',\n",
       " 'L1_S25_D2421',\n",
       " 'L1_S25_D2424',\n",
       " 'L1_S25_D2427',\n",
       " 'L1_S25_D2430',\n",
       " 'L1_S25_D2432',\n",
       " 'L1_S25_D2434',\n",
       " 'L1_S25_D2436',\n",
       " 'L1_S25_D2438',\n",
       " 'L1_S25_D2440',\n",
       " 'L1_S25_D2442',\n",
       " 'L1_S25_D2444',\n",
       " 'L1_S25_D2445',\n",
       " 'L1_S25_D2446',\n",
       " 'L1_S25_D2448',\n",
       " 'L1_S25_D2450',\n",
       " 'L1_S25_D2452',\n",
       " 'L1_S25_D2453',\n",
       " 'L1_S25_D2455',\n",
       " 'L1_S25_D2457',\n",
       " 'L1_S25_D2459',\n",
       " 'L1_S25_D2461',\n",
       " 'L1_S25_D2463',\n",
       " 'L1_S25_D2465',\n",
       " 'L1_S25_D2467',\n",
       " 'L1_S25_D2469',\n",
       " 'L1_S25_D2471',\n",
       " 'L1_S25_D2474',\n",
       " 'L1_S25_D2477',\n",
       " 'L1_S25_D2480',\n",
       " 'L1_S25_D2483',\n",
       " 'L1_S25_D2486',\n",
       " 'L1_S25_D2489',\n",
       " 'L1_S25_D2492',\n",
       " 'L1_S25_D2495',\n",
       " 'L1_S25_D2497',\n",
       " 'L1_S25_D2499',\n",
       " 'L1_S25_D2501',\n",
       " 'L1_S25_D2502',\n",
       " 'L1_S25_D2503',\n",
       " 'L1_S25_D2505',\n",
       " 'L1_S25_D2507',\n",
       " 'L1_S25_D2509',\n",
       " 'L1_S25_D2511',\n",
       " 'L1_S25_D2513',\n",
       " 'L1_S25_D2515',\n",
       " 'L1_S25_D2518',\n",
       " 'L1_S25_D2522',\n",
       " 'L1_S25_D2527',\n",
       " 'L1_S25_D2532',\n",
       " 'L1_S25_D2537',\n",
       " 'L1_S25_D2542',\n",
       " 'L1_S25_D2547',\n",
       " 'L1_S25_D2551',\n",
       " 'L1_S25_D2556',\n",
       " 'L1_S25_D2561',\n",
       " 'L1_S25_D2566',\n",
       " 'L1_S25_D2571',\n",
       " 'L1_S25_D2576',\n",
       " 'L1_S25_D2581',\n",
       " 'L1_S25_D2586',\n",
       " 'L1_S25_D2591',\n",
       " 'L1_S25_D2596',\n",
       " 'L1_S25_D2600',\n",
       " 'L1_S25_D2605',\n",
       " 'L1_S25_D2610',\n",
       " 'L1_S25_D2615',\n",
       " 'L1_S25_D2620',\n",
       " 'L1_S25_D2625',\n",
       " 'L1_S25_D2629',\n",
       " 'L1_S25_D2634',\n",
       " 'L1_S25_D2639',\n",
       " 'L1_S25_D2644',\n",
       " 'L1_S25_D2649',\n",
       " 'L1_S25_D2654',\n",
       " 'L1_S25_D2659',\n",
       " 'L1_S25_D2664',\n",
       " 'L1_S25_D2669',\n",
       " 'L1_S25_D2674',\n",
       " 'L1_S25_D2679',\n",
       " 'L1_S25_D2684',\n",
       " 'L1_S25_D2689',\n",
       " 'L1_S25_D2694',\n",
       " 'L1_S25_D2699',\n",
       " 'L1_S25_D2704',\n",
       " 'L1_S25_D2709',\n",
       " 'L1_S25_D2713',\n",
       " 'L1_S25_D2715',\n",
       " 'L1_S25_D2717',\n",
       " 'L1_S25_D2719',\n",
       " 'L1_S25_D2721',\n",
       " 'L1_S25_D2723',\n",
       " 'L1_S25_D2725',\n",
       " 'L1_S25_D2727',\n",
       " 'L1_S25_D2728',\n",
       " 'L1_S25_D2729',\n",
       " 'L1_S25_D2731',\n",
       " 'L1_S25_D2733',\n",
       " 'L1_S25_D2735',\n",
       " 'L1_S25_D2736',\n",
       " 'L1_S25_D2738',\n",
       " 'L1_S25_D2740',\n",
       " 'L1_S25_D2742',\n",
       " 'L1_S25_D2744',\n",
       " 'L1_S25_D2746',\n",
       " 'L1_S25_D2748',\n",
       " 'L1_S25_D2750',\n",
       " 'L1_S25_D2752',\n",
       " 'L1_S25_D2754',\n",
       " 'L1_S25_D2757',\n",
       " 'L1_S25_D2760',\n",
       " 'L1_S25_D2763',\n",
       " 'L1_S25_D2766',\n",
       " 'L1_S25_D2769',\n",
       " 'L1_S25_D2772',\n",
       " 'L1_S25_D2775',\n",
       " 'L1_S25_D2778',\n",
       " 'L1_S25_D2780',\n",
       " 'L1_S25_D2782',\n",
       " 'L1_S25_D2784',\n",
       " 'L1_S25_D2785',\n",
       " 'L1_S25_D2786',\n",
       " 'L1_S25_D2788',\n",
       " 'L1_S25_D2790',\n",
       " 'L1_S25_D2792',\n",
       " 'L1_S25_D2794',\n",
       " 'L1_S25_D2796',\n",
       " 'L1_S25_D2798',\n",
       " 'L1_S25_D2801',\n",
       " 'L1_S25_D2805',\n",
       " 'L1_S25_D2810',\n",
       " 'L1_S25_D2815',\n",
       " 'L1_S25_D2820',\n",
       " 'L1_S25_D2825',\n",
       " 'L1_S25_D2830',\n",
       " 'L1_S25_D2834',\n",
       " 'L1_S25_D2839',\n",
       " 'L1_S25_D2844',\n",
       " 'L1_S25_D2849',\n",
       " 'L1_S25_D2854',\n",
       " 'L1_S25_D2859',\n",
       " 'L1_S25_D2864',\n",
       " 'L1_S25_D2869',\n",
       " 'L1_S25_D2874',\n",
       " 'L1_S25_D2879',\n",
       " 'L1_S25_D2883',\n",
       " 'L1_S25_D2888',\n",
       " 'L1_S25_D2893',\n",
       " 'L1_S25_D2898',\n",
       " 'L1_S25_D2903',\n",
       " 'L1_S25_D2908',\n",
       " 'L1_S25_D2912',\n",
       " 'L1_S25_D2917',\n",
       " 'L1_S25_D2922',\n",
       " 'L1_S25_D2927',\n",
       " 'L1_S25_D2932',\n",
       " 'L1_S25_D2937',\n",
       " 'L1_S25_D2942',\n",
       " 'L1_S25_D2947',\n",
       " 'L1_S25_D2952',\n",
       " 'L1_S25_D2957',\n",
       " 'L1_S25_D2962',\n",
       " 'L1_S25_D2967',\n",
       " 'L1_S25_D2972',\n",
       " 'L1_S25_D2977',\n",
       " 'L1_S25_D2982',\n",
       " 'L1_S25_D2987',\n",
       " 'L1_S25_D2992',\n",
       " 'L1_S25_D2996',\n",
       " 'L1_S25_D2998',\n",
       " 'L1_S25_D3000',\n",
       " 'L1_S25_D3002',\n",
       " 'L1_S25_D3004',\n",
       " 'L1_S25_D3006',\n",
       " 'L1_S25_D3008',\n",
       " 'L1_S25_D3010',\n",
       " 'L1_S25_D3011',\n",
       " 'L1_S25_D3012',\n",
       " 'L1_S25_D3014',\n",
       " 'L1_S25_D3016',\n",
       " 'L1_S25_D3018',\n",
       " 'L1_S25_D3019',\n",
       " 'L1_S25_D3021',\n",
       " 'L1_S25_D3023',\n",
       " 'L1_S25_D3025',\n",
       " 'L1_S25_D3027',\n",
       " 'L1_S25_D3029',\n",
       " 'L1_S25_D3031',\n",
       " 'L1_S25_D3033',\n",
       " 'L1_S25_D3035',\n",
       " 'L2_S26_D3037',\n",
       " 'L2_S27_D3130',\n",
       " 'L2_S28_D3223',\n",
       " 'L3_S29_D3316',\n",
       " 'L3_S30_D3496',\n",
       " 'L3_S31_D3836',\n",
       " 'L3_S32_D3852',\n",
       " 'L3_S33_D3856',\n",
       " 'L3_S34_D3875',\n",
       " 'L3_S35_D3886',\n",
       " 'L3_S36_D3919',\n",
       " 'L3_S37_D3942',\n",
       " 'L3_S38_D3953',\n",
       " 'L3_S39_D3966',\n",
       " 'L3_S40_D3981',\n",
       " 'L3_S41_D3997',\n",
       " 'L3_S42_D4029',\n",
       " 'L3_S43_D4062',\n",
       " 'L3_S44_D4101',\n",
       " 'L3_S45_D4125',\n",
       " 'L3_S46_D4135',\n",
       " 'L3_S47_D4140',\n",
       " 'L3_S48_D4194',\n",
       " 'L3_S49_D4208',\n",
       " 'L3_S50_D4242',\n",
       " 'L3_S51_D4255']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usefuldatefeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_mindate():\n",
    "    directory = '../data/'\n",
    "    trainfile = 'train_date.csv'\n",
    "    testfile = 'test_date.csv'\n",
    "    \n",
    "    features = None\n",
    "    subset = None\n",
    "    \n",
    "    for i, chunk in enumerate(pd.read_csv(directory + trainfile,\n",
    "                                          usecols=usefuldatefeatures,\n",
    "                                          chunksize=50000,\n",
    "                                          low_memory=False)):\n",
    "        print(i)\n",
    "        \n",
    "        if features is None:\n",
    "            features = list(chunk.columns)\n",
    "            features.remove('Id')\n",
    "        \n",
    "        df_mindate_chunk = chunk[['Id']].copy()\n",
    "        df_mindate_chunk['mindate'] = chunk[features].min(axis=1).values\n",
    "        df_mindate_chunk['maxdate'] = chunk[features].max(axis=1).values \n",
    "        df_mindate_chunk['diff'] = df_mindate_chunk['maxdate'] - df_mindate_chunk['mindate']\n",
    "        \n",
    "        if subset is None:\n",
    "            subset = df_mindate_chunk.copy()\n",
    "        else:\n",
    "            subset = pd.concat([subset, df_mindate_chunk])\n",
    "            \n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "    for i, chunk in enumerate(pd.read_csv(directory + testfile,\n",
    "                                          usecols=usefuldatefeatures,\n",
    "                                          chunksize=50000,\n",
    "                                          low_memory=False)):\n",
    "        print(i)\n",
    "        \n",
    "        df_mindate_chunk = chunk[['Id']].copy()\n",
    "        df_mindate_chunk['mindate'] = chunk[features].min(axis=1).values\n",
    "        df_mindate_chunk['maxdate'] = chunk[features].max(axis=1).values \n",
    "        df_mindate_chunk['diff'] = df_mindate_chunk['maxdate'] - df_mindate_chunk['mindate']\n",
    "        subset = pd.concat([subset, df_mindate_chunk])\n",
    "        \n",
    "        del chunk\n",
    "        gc.collect()      \n",
    "        \n",
    "    return subset\n",
    "\n",
    "\n",
    "df_mindate_0 = get_mindate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>82.24</td>\n",
       "      <td>87.29</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1313.12</td>\n",
       "      <td>1315.75</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1624.42</td>\n",
       "      <td>5.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1154.16</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>602.64</td>\n",
       "      <td>606.02</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>1331.66</td>\n",
       "      <td>1339.73</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>1662.63</td>\n",
       "      <td>1664.04</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>791.22</td>\n",
       "      <td>804.36</td>\n",
       "      <td>13.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>517.64</td>\n",
       "      <td>518.08</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>156.27</td>\n",
       "      <td>157.89</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "      <td>1104.78</td>\n",
       "      <td>1105.95</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27</td>\n",
       "      <td>392.85</td>\n",
       "      <td>401.41</td>\n",
       "      <td>8.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28</td>\n",
       "      <td>55.44</td>\n",
       "      <td>62.10</td>\n",
       "      <td>6.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31</td>\n",
       "      <td>98.99</td>\n",
       "      <td>99.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34</td>\n",
       "      <td>354.51</td>\n",
       "      <td>365.38</td>\n",
       "      <td>10.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38</td>\n",
       "      <td>1633.80</td>\n",
       "      <td>1636.37</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41</td>\n",
       "      <td>476.06</td>\n",
       "      <td>476.57</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44</td>\n",
       "      <td>1532.42</td>\n",
       "      <td>1542.00</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47</td>\n",
       "      <td>263.21</td>\n",
       "      <td>263.44</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>675.84</td>\n",
       "      <td>677.68</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>52</td>\n",
       "      <td>966.77</td>\n",
       "      <td>991.61</td>\n",
       "      <td>24.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "      <td>1341.05</td>\n",
       "      <td>1346.19</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>56</td>\n",
       "      <td>886.18</td>\n",
       "      <td>890.10</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>57</td>\n",
       "      <td>609.56</td>\n",
       "      <td>611.48</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>63</td>\n",
       "      <td>656.22</td>\n",
       "      <td>668.04</td>\n",
       "      <td>11.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>68</td>\n",
       "      <td>1450.09</td>\n",
       "      <td>1450.84</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>70</td>\n",
       "      <td>187.57</td>\n",
       "      <td>188.97</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>71</td>\n",
       "      <td>1458.06</td>\n",
       "      <td>1460.32</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>72</td>\n",
       "      <td>1293.17</td>\n",
       "      <td>1297.48</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>73</td>\n",
       "      <td>319.66</td>\n",
       "      <td>321.29</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33718</th>\n",
       "      <td>2367436</td>\n",
       "      <td>1567.97</td>\n",
       "      <td>1574.73</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33719</th>\n",
       "      <td>2367438</td>\n",
       "      <td>324.72</td>\n",
       "      <td>333.65</td>\n",
       "      <td>8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33720</th>\n",
       "      <td>2367441</td>\n",
       "      <td>1341.05</td>\n",
       "      <td>1346.22</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33721</th>\n",
       "      <td>2367445</td>\n",
       "      <td>1214.45</td>\n",
       "      <td>1216.07</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33722</th>\n",
       "      <td>2367446</td>\n",
       "      <td>520.59</td>\n",
       "      <td>522.39</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33723</th>\n",
       "      <td>2367447</td>\n",
       "      <td>1174.75</td>\n",
       "      <td>1189.65</td>\n",
       "      <td>14.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33724</th>\n",
       "      <td>2367448</td>\n",
       "      <td>320.60</td>\n",
       "      <td>322.32</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33725</th>\n",
       "      <td>2367449</td>\n",
       "      <td>553.66</td>\n",
       "      <td>555.14</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33726</th>\n",
       "      <td>2367450</td>\n",
       "      <td>1379.68</td>\n",
       "      <td>1399.93</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33727</th>\n",
       "      <td>2367451</td>\n",
       "      <td>1394.35</td>\n",
       "      <td>1395.74</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33728</th>\n",
       "      <td>2367453</td>\n",
       "      <td>707.04</td>\n",
       "      <td>745.26</td>\n",
       "      <td>38.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33729</th>\n",
       "      <td>2367454</td>\n",
       "      <td>1568.88</td>\n",
       "      <td>1575.65</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33730</th>\n",
       "      <td>2367455</td>\n",
       "      <td>877.10</td>\n",
       "      <td>886.20</td>\n",
       "      <td>9.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33731</th>\n",
       "      <td>2367456</td>\n",
       "      <td>1272.59</td>\n",
       "      <td>1290.23</td>\n",
       "      <td>17.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33732</th>\n",
       "      <td>2367457</td>\n",
       "      <td>1272.59</td>\n",
       "      <td>1290.23</td>\n",
       "      <td>17.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33733</th>\n",
       "      <td>2367463</td>\n",
       "      <td>986.13</td>\n",
       "      <td>1021.64</td>\n",
       "      <td>35.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33734</th>\n",
       "      <td>2367465</td>\n",
       "      <td>606.18</td>\n",
       "      <td>609.73</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33735</th>\n",
       "      <td>2367467</td>\n",
       "      <td>606.18</td>\n",
       "      <td>619.99</td>\n",
       "      <td>13.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33736</th>\n",
       "      <td>2367468</td>\n",
       "      <td>1328.77</td>\n",
       "      <td>1333.50</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33737</th>\n",
       "      <td>2367470</td>\n",
       "      <td>364.71</td>\n",
       "      <td>366.99</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33738</th>\n",
       "      <td>2367475</td>\n",
       "      <td>896.98</td>\n",
       "      <td>904.17</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33739</th>\n",
       "      <td>2367477</td>\n",
       "      <td>571.03</td>\n",
       "      <td>572.81</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33740</th>\n",
       "      <td>2367479</td>\n",
       "      <td>825.92</td>\n",
       "      <td>829.38</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33741</th>\n",
       "      <td>2367481</td>\n",
       "      <td>991.81</td>\n",
       "      <td>1007.50</td>\n",
       "      <td>15.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33742</th>\n",
       "      <td>2367482</td>\n",
       "      <td>230.53</td>\n",
       "      <td>231.98</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33743</th>\n",
       "      <td>2367483</td>\n",
       "      <td>653.85</td>\n",
       "      <td>655.45</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33744</th>\n",
       "      <td>2367485</td>\n",
       "      <td>907.34</td>\n",
       "      <td>911.29</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33745</th>\n",
       "      <td>2367486</td>\n",
       "      <td>185.92</td>\n",
       "      <td>186.32</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33746</th>\n",
       "      <td>2367489</td>\n",
       "      <td>570.85</td>\n",
       "      <td>572.67</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33747</th>\n",
       "      <td>2367494</td>\n",
       "      <td>1412.80</td>\n",
       "      <td>1413.18</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2367495 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  mindate  maxdate   diff\n",
       "0            4    82.24    87.29   5.05\n",
       "1            6  1313.12  1315.75   2.63\n",
       "2            7  1618.70  1624.42   5.72\n",
       "3            9  1149.20  1154.16   4.96\n",
       "4           11   602.64   606.02   3.38\n",
       "5           13  1331.66  1339.73   8.07\n",
       "6           14  1662.63  1664.04   1.41\n",
       "7           16   791.22   804.36  13.14\n",
       "8           18   517.64   518.08   0.44\n",
       "9           23   156.27   157.89   1.62\n",
       "10          26  1104.78  1105.95   1.17\n",
       "11          27   392.85   401.41   8.56\n",
       "12          28    55.44    62.10   6.66\n",
       "13          31    98.99    99.67   0.68\n",
       "14          34   354.51   365.38  10.87\n",
       "15          38  1633.80  1636.37   2.57\n",
       "16          41   476.06   476.57   0.51\n",
       "17          44  1532.42  1542.00   9.58\n",
       "18          47   263.21   263.44   0.23\n",
       "19          49   675.84   677.68   1.84\n",
       "20          52   966.77   991.61  24.84\n",
       "21          55  1341.05  1346.19   5.14\n",
       "22          56   886.18   890.10   3.92\n",
       "23          57   609.56   611.48   1.92\n",
       "24          63   656.22   668.04  11.82\n",
       "25          68  1450.09  1450.84   0.75\n",
       "26          70   187.57   188.97   1.40\n",
       "27          71  1458.06  1460.32   2.26\n",
       "28          72  1293.17  1297.48   4.31\n",
       "29          73   319.66   321.29   1.63\n",
       "...        ...      ...      ...    ...\n",
       "33718  2367436  1567.97  1574.73   6.76\n",
       "33719  2367438   324.72   333.65   8.93\n",
       "33720  2367441  1341.05  1346.22   5.17\n",
       "33721  2367445  1214.45  1216.07   1.62\n",
       "33722  2367446   520.59   522.39   1.80\n",
       "33723  2367447  1174.75  1189.65  14.90\n",
       "33724  2367448   320.60   322.32   1.72\n",
       "33725  2367449   553.66   555.14   1.48\n",
       "33726  2367450  1379.68  1399.93  20.25\n",
       "33727  2367451  1394.35  1395.74   1.39\n",
       "33728  2367453   707.04   745.26  38.22\n",
       "33729  2367454  1568.88  1575.65   6.77\n",
       "33730  2367455   877.10   886.20   9.10\n",
       "33731  2367456  1272.59  1290.23  17.64\n",
       "33732  2367457  1272.59  1290.23  17.64\n",
       "33733  2367463   986.13  1021.64  35.51\n",
       "33734  2367465   606.18   609.73   3.55\n",
       "33735  2367467   606.18   619.99  13.81\n",
       "33736  2367468  1328.77  1333.50   4.73\n",
       "33737  2367470   364.71   366.99   2.28\n",
       "33738  2367475   896.98   904.17   7.19\n",
       "33739  2367477   571.03   572.81   1.78\n",
       "33740  2367479   825.92   829.38   3.46\n",
       "33741  2367481   991.81  1007.50  15.69\n",
       "33742  2367482   230.53   231.98   1.45\n",
       "33743  2367483   653.85   655.45   1.60\n",
       "33744  2367485   907.34   911.29   3.95\n",
       "33745  2367486   185.92   186.32   0.40\n",
       "33746  2367489   570.85   572.67   1.82\n",
       "33747  2367494  1412.80  1413.18   0.38\n",
       "\n",
       "[2367495 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mindate_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>diff</th>\n",
       "      <th>mindate_id_diff</th>\n",
       "      <th>mindate_id_diff_reverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>510783</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-140759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25556</th>\n",
       "      <td>651542</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.53</td>\n",
       "      <td>140759.0</td>\n",
       "      <td>543349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>108193</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-543349.0</td>\n",
       "      <td>-322219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15108</th>\n",
       "      <td>430412</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>322219.0</td>\n",
       "      <td>-13085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21628</th>\n",
       "      <td>443497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>-69868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6783</th>\n",
       "      <td>513365</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>69868.0</td>\n",
       "      <td>-3711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8658</th>\n",
       "      <td>517076</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>3711.0</td>\n",
       "      <td>-3140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10251</th>\n",
       "      <td>520216</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>-1046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10490</th>\n",
       "      <td>521262</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>-53267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37271</th>\n",
       "      <td>574529</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>53267.0</td>\n",
       "      <td>-6182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>580711</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>6182.0</td>\n",
       "      <td>-7088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43761</th>\n",
       "      <td>587799</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>7088.0</td>\n",
       "      <td>-9001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48264</th>\n",
       "      <td>596800</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>9001.0</td>\n",
       "      <td>-58257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27713</th>\n",
       "      <td>655057</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>58257.0</td>\n",
       "      <td>-7978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31740</th>\n",
       "      <td>663035</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>-6482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34483</th>\n",
       "      <td>669517</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>6482.0</td>\n",
       "      <td>-65821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>735338</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.51</td>\n",
       "      <td>65821.0</td>\n",
       "      <td>-1926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18403</th>\n",
       "      <td>737264</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>-4402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21080</th>\n",
       "      <td>741666</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>4402.0</td>\n",
       "      <td>-66721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>808387</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>66721.0</td>\n",
       "      <td>578341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15100</th>\n",
       "      <td>230046</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-578341.0</td>\n",
       "      <td>-3301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16638</th>\n",
       "      <td>233347</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>-2834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18075</th>\n",
       "      <td>236181</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2834.0</td>\n",
       "      <td>-10267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23232</th>\n",
       "      <td>246448</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>10267.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23233</th>\n",
       "      <td>246449</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-65606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>312055</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>65606.0</td>\n",
       "      <td>-1483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>313538</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>-6367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>319905</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.52</td>\n",
       "      <td>6367.0</td>\n",
       "      <td>-4259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11965</th>\n",
       "      <td>324164</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>4259.0</td>\n",
       "      <td>-54244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39218</th>\n",
       "      <td>378408</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>54244.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17234</th>\n",
       "      <td>2234852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9851.0</td>\n",
       "      <td>-1467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17958</th>\n",
       "      <td>2236319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17969</th>\n",
       "      <td>2236342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-19431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27978</th>\n",
       "      <td>2255773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19431.0</td>\n",
       "      <td>-3931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29767</th>\n",
       "      <td>2259704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3931.0</td>\n",
       "      <td>-10834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35339</th>\n",
       "      <td>2270538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10834.0</td>\n",
       "      <td>-950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35814</th>\n",
       "      <td>2271488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35673</th>\n",
       "      <td>2271489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35815</th>\n",
       "      <td>2271490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35674</th>\n",
       "      <td>2271491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36717</th>\n",
       "      <td>2273571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>-11935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42781</th>\n",
       "      <td>2285506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11935.0</td>\n",
       "      <td>-795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43131</th>\n",
       "      <td>2286301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>795.0</td>\n",
       "      <td>-6003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46257</th>\n",
       "      <td>2292304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6003.0</td>\n",
       "      <td>-1388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46763</th>\n",
       "      <td>2293692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>-6266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49923</th>\n",
       "      <td>2299958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6266.0</td>\n",
       "      <td>-2423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>2302381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2423.0</td>\n",
       "      <td>-1851.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>2304232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>-2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>2306237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>-1369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>2307606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>-1113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>2308719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>-2100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5392</th>\n",
       "      <td>2310819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>-6246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <td>2317065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6246.0</td>\n",
       "      <td>-2292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>2319357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2292.0</td>\n",
       "      <td>-287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9820</th>\n",
       "      <td>2319644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287.0</td>\n",
       "      <td>-2983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11319</th>\n",
       "      <td>2322627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2983.0</td>\n",
       "      <td>-805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11719</th>\n",
       "      <td>2323432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805.0</td>\n",
       "      <td>-1297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12370</th>\n",
       "      <td>2324729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>-6721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15718</th>\n",
       "      <td>2331450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6721.0</td>\n",
       "      <td>-21898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26575</th>\n",
       "      <td>2353348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21898.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2367495 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  mindate  maxdate  diff  mindate_id_diff  \\\n",
       "5472    510783     0.00     1.61  1.61              NaN   \n",
       "25556   651542     0.00     1.53  1.53         140759.0   \n",
       "4038    108193     0.01     1.61  1.60        -543349.0   \n",
       "15108   430412     0.01     1.53  1.52         322219.0   \n",
       "21628   443497     0.01     1.53  1.52          13085.0   \n",
       "6783    513365     0.01     1.53  1.52          69868.0   \n",
       "8658    517076     0.01     1.53  1.52           3711.0   \n",
       "10251   520216     0.01     1.52  1.51           3140.0   \n",
       "10490   521262     0.01     1.53  1.52           1046.0   \n",
       "37271   574529     0.01     1.52  1.51          53267.0   \n",
       "40477   580711     0.01     1.52  1.51           6182.0   \n",
       "43761   587799     0.01     1.52  1.51           7088.0   \n",
       "48264   596800     0.01     1.52  1.51           9001.0   \n",
       "27713   655057     0.01     1.52  1.51          58257.0   \n",
       "31740   663035     0.01     1.52  1.51           7978.0   \n",
       "34483   669517     0.01     1.52  1.51           6482.0   \n",
       "17906   735338     0.01     1.52  1.51          65821.0   \n",
       "18403   737264     0.01     1.53  1.52           1926.0   \n",
       "21080   741666     0.01     1.53  1.52           4402.0   \n",
       "4466    808387     0.01     1.53  1.52          66721.0   \n",
       "15100   230046     0.02     1.53  1.51        -578341.0   \n",
       "16638   233347     0.02     1.53  1.51           3301.0   \n",
       "18075   236181     0.02     1.54  1.52           2834.0   \n",
       "23232   246448     0.02     1.53  1.51          10267.0   \n",
       "23233   246449     0.02     1.53  1.51              1.0   \n",
       "5918    312055     0.02     1.53  1.51          65606.0   \n",
       "6684    313538     0.02     1.53  1.51           1483.0   \n",
       "10062   319905     0.02     1.54  1.52           6367.0   \n",
       "11965   324164     0.02     1.53  1.51           4259.0   \n",
       "39218   378408     0.02     1.53  1.51          54244.0   \n",
       "...        ...      ...      ...   ...              ...   \n",
       "17234  2234852      NaN      NaN   NaN           9851.0   \n",
       "17958  2236319      NaN      NaN   NaN           1467.0   \n",
       "17969  2236342      NaN      NaN   NaN             23.0   \n",
       "27978  2255773      NaN      NaN   NaN          19431.0   \n",
       "29767  2259704      NaN      NaN   NaN           3931.0   \n",
       "35339  2270538      NaN      NaN   NaN          10834.0   \n",
       "35814  2271488      NaN      NaN   NaN            950.0   \n",
       "35673  2271489      NaN      NaN   NaN              1.0   \n",
       "35815  2271490      NaN      NaN   NaN              1.0   \n",
       "35674  2271491      NaN      NaN   NaN              1.0   \n",
       "36717  2273571      NaN      NaN   NaN           2080.0   \n",
       "42781  2285506      NaN      NaN   NaN          11935.0   \n",
       "43131  2286301      NaN      NaN   NaN            795.0   \n",
       "46257  2292304      NaN      NaN   NaN           6003.0   \n",
       "46763  2293692      NaN      NaN   NaN           1388.0   \n",
       "49923  2299958      NaN      NaN   NaN           6266.0   \n",
       "1246   2302381      NaN      NaN   NaN           2423.0   \n",
       "2064   2304232      NaN      NaN   NaN           1851.0   \n",
       "3064   2306237      NaN      NaN   NaN           2005.0   \n",
       "3840   2307606      NaN      NaN   NaN           1369.0   \n",
       "4303   2308719      NaN      NaN   NaN           1113.0   \n",
       "5392   2310819      NaN      NaN   NaN           2100.0   \n",
       "8524   2317065      NaN      NaN   NaN           6246.0   \n",
       "9679   2319357      NaN      NaN   NaN           2292.0   \n",
       "9820   2319644      NaN      NaN   NaN            287.0   \n",
       "11319  2322627      NaN      NaN   NaN           2983.0   \n",
       "11719  2323432      NaN      NaN   NaN            805.0   \n",
       "12370  2324729      NaN      NaN   NaN           1297.0   \n",
       "15718  2331450      NaN      NaN   NaN           6721.0   \n",
       "26575  2353348      NaN      NaN   NaN          21898.0   \n",
       "\n",
       "       mindate_id_diff_reverse  \n",
       "5472                 -140759.0  \n",
       "25556                 543349.0  \n",
       "4038                 -322219.0  \n",
       "15108                 -13085.0  \n",
       "21628                 -69868.0  \n",
       "6783                   -3711.0  \n",
       "8658                   -3140.0  \n",
       "10251                  -1046.0  \n",
       "10490                 -53267.0  \n",
       "37271                  -6182.0  \n",
       "40477                  -7088.0  \n",
       "43761                  -9001.0  \n",
       "48264                 -58257.0  \n",
       "27713                  -7978.0  \n",
       "31740                  -6482.0  \n",
       "34483                 -65821.0  \n",
       "17906                  -1926.0  \n",
       "18403                  -4402.0  \n",
       "21080                 -66721.0  \n",
       "4466                  578341.0  \n",
       "15100                  -3301.0  \n",
       "16638                  -2834.0  \n",
       "18075                 -10267.0  \n",
       "23232                     -1.0  \n",
       "23233                 -65606.0  \n",
       "5918                   -1483.0  \n",
       "6684                   -6367.0  \n",
       "10062                  -4259.0  \n",
       "11965                 -54244.0  \n",
       "39218                     -1.0  \n",
       "...                        ...  \n",
       "17234                  -1467.0  \n",
       "17958                    -23.0  \n",
       "17969                 -19431.0  \n",
       "27978                  -3931.0  \n",
       "29767                 -10834.0  \n",
       "35339                   -950.0  \n",
       "35814                     -1.0  \n",
       "35673                     -1.0  \n",
       "35815                     -1.0  \n",
       "35674                  -2080.0  \n",
       "36717                 -11935.0  \n",
       "42781                   -795.0  \n",
       "43131                  -6003.0  \n",
       "46257                  -1388.0  \n",
       "46763                  -6266.0  \n",
       "49923                  -2423.0  \n",
       "1246                   -1851.0  \n",
       "2064                   -2005.0  \n",
       "3064                   -1369.0  \n",
       "3840                   -1113.0  \n",
       "4303                   -2100.0  \n",
       "5392                   -6246.0  \n",
       "8524                   -2292.0  \n",
       "9679                    -287.0  \n",
       "9820                   -2983.0  \n",
       "11319                   -805.0  \n",
       "11719                  -1297.0  \n",
       "12370                  -6721.0  \n",
       "15718                 -21898.0  \n",
       "26575                      NaN  \n",
       "\n",
       "[2367495 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mindate_0.sort_values(by=['mindate', 'Id'], inplace=True)\n",
    "df_mindate_1 = df_mindate_0\n",
    "df_mindate_1['mindate_id_diff'] = df_mindate_1.Id.diff()\n",
    "\n",
    "midr = np.full_like(df_mindate_1.mindate_id_diff.values, np.nan)\n",
    "midr[0:-1] = -df_mindate_1.mindate_id_diff.values[1:]\n",
    "\n",
    "df_mindate_1['mindate_id_diff_reverse'] = midr\n",
    "df_mindate = df_mindate_1 \n",
    "\n",
    "df_mindate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mcc(tp, tn, fp, fn):\n",
    "    sup = tp * tn - fp * fn\n",
    "    inf = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    if inf == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sup / np.sqrt(inf)\n",
    "\n",
    "\n",
    "def eval_mcc(y_true, y_prob, show=False):\n",
    "    idx = np.argsort(y_prob)\n",
    "    y_true_sort = y_true[idx]\n",
    "    n = y_true.shape[0]\n",
    "    nump = 1.0 * np.sum(y_true)  # number of positive\n",
    "    numn = n - nump  # number of negative\n",
    "    tp = nump\n",
    "    tn = 0.0\n",
    "    fp = numn\n",
    "    fn = 0.0\n",
    "    best_mcc = 0.0\n",
    "    best_id = -1\n",
    "    mccs = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if y_true_sort[i] == 1:\n",
    "            tp -= 1.0\n",
    "            fn += 1.0\n",
    "        else:\n",
    "            fp -= 1.0\n",
    "            tn += 1.0\n",
    "        new_mcc = mcc(tp, tn, fp, fn)\n",
    "        mccs[i] = new_mcc\n",
    "        if new_mcc >= best_mcc:\n",
    "            best_mcc = new_mcc\n",
    "            best_id = i\n",
    "    if show:\n",
    "        best_proba = y_prob[idx[best_id]]\n",
    "        y_pred = (y_prob > best_proba).astype(int)\n",
    "        return best_proba, best_mcc, y_pred\n",
    "    else:\n",
    "        return best_mcc\n",
    "\n",
    "\n",
    "def mcc_eval(y_prob, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    best_mcc = eval_mcc(y_true, y_prob)\n",
    "    return 'MCC', best_mcc\n",
    "\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n",
    "\n",
    "\n",
    "def LeaveOneOut(data1, data2, columnName, useLOO=False):\n",
    "    grpOutcomes = data1.groupby(columnName)['Response'].mean().reset_index()\n",
    "    grpCount = data1.groupby(columnName)['Response'].count().reset_index()\n",
    "    grpOutcomes['cnt'] = grpCount.Response\n",
    "    #if(useLOO):\n",
    "    #    grpOutcomes = grpOutcomes[grpOutcomes.cnt > 1]\n",
    "    if(useLOO): \n",
    "        grpOutcomes = grpOutcomes[grpOutcomes.cnt > 30]\n",
    "    else: \n",
    "        grpOutcomes = grpOutcomes[grpOutcomes.cnt >= 30]\n",
    "        \n",
    "    grpOutcomes.drop('cnt', inplace=True, axis=1)\n",
    "    outcomes = data2['Response'].values\n",
    "    x = pd.merge(data2[[columnName, 'Response']], grpOutcomes,\n",
    "                 suffixes=('x_', ''),\n",
    "                 how='left',\n",
    "                 on=columnName,\n",
    "                 left_index=True)['Response']\n",
    "    if(useLOO):\n",
    "        x = ((x*x.shape[0])-outcomes)/(x.shape[0]-1)\n",
    "        #  x = x + np.random.normal(0, .01, x.shape[0])\n",
    "    return x.fillna(x.mean())\n",
    "\n",
    "\n",
    "def GrabData():\n",
    "    directory = '../data/'\n",
    "    trainfiles = ['train_categorical.csv',\n",
    "                  'train_date.csv',\n",
    "                  'train_numeric.csv']\n",
    "    testfiles = ['test_categorical.csv',\n",
    "                 'test_date.csv',\n",
    "                 'test_numeric.csv']\n",
    "\n",
    "    cols = [['Id',\n",
    "             'L1_S24_F1559', 'L3_S32_F3851',\n",
    "             'L1_S24_F1827', 'L1_S24_F1582',\n",
    "             'L3_S32_F3854', 'L1_S24_F1510',\n",
    "             'L1_S24_F1525'],\n",
    "            ['Id',\n",
    "             'L3_S30_D3496', 'L3_S30_D3506',\n",
    "             'L3_S30_D3501', 'L3_S30_D3516',\n",
    "             'L3_S30_D3511',\n",
    "             #added this piece for data vars\n",
    "             'L0_S2_D34', 'L0_S3_D70', 'L0_S7_D137', 'L3_S29_D3474',\n",
    "             #'L3_S32_D3852', 'L3_S33_D3856', 'L3_S34_D3875', 'L3_S35_D3886',\n",
    "             #'L3_S49_D4208'\n",
    "            ],\n",
    "            ['Id',\n",
    "             'L1_S24_F1846', 'L3_S32_F3850',\n",
    "             'L1_S24_F1695', 'L1_S24_F1632',\n",
    "             'L3_S33_F3855', 'L1_S24_F1604',\n",
    "             'L3_S29_F3407', \n",
    "             'L3_S33_F3865',\n",
    "             'L3_S38_F3952', 'L1_S24_F1723',\n",
    "             #added this piece for numeric vars\n",
    "             'L0_S0_F18', 'L0_S0_F20', \n",
    "             'L0_S4_F104', \n",
    "             'L0_S10_F264', \n",
    "                            \n",
    "             'L3_S29_F3327', 'L3_S29_F3339', 'L3_S29_F3342',\n",
    "             'L3_S29_F3382', \n",
    "               \n",
    "             'L3_S30_F3704',\n",
    "             'L3_S30_F3754', 'L3_S30_F3759',\n",
    "             'L3_S33_F3857', 'L3_S33_F3859',\n",
    "             'L3_S36_F3920',\n",
    "             \n",
    "             'Response']]\n",
    "    traindata = None\n",
    "    testdata = None\n",
    "    for i, f in enumerate(trainfiles):\n",
    "        print(f)\n",
    "        subset = None\n",
    "        for i, chunk in enumerate(pd.read_csv(directory + f,\n",
    "                                              usecols=cols[i],\n",
    "                                              chunksize=50000,\n",
    "                                              low_memory=False)):\n",
    "            print(i)\n",
    "            if subset is None:\n",
    "                subset = chunk.copy()\n",
    "            else:\n",
    "                subset = pd.concat([subset, chunk])\n",
    "            del chunk\n",
    "            gc.collect()\n",
    "        if traindata is None:\n",
    "            traindata = subset.copy()\n",
    "        else:\n",
    "            traindata = pd.merge(traindata, subset.copy(), on=\"Id\")\n",
    "        del subset\n",
    "        gc.collect()\n",
    "    del cols[2][-1]  # Test doesn't have response!\n",
    "    for i, f in enumerate(testfiles):\n",
    "        print(f)\n",
    "        subset = None\n",
    "        for i, chunk in enumerate(pd.read_csv(directory + f,\n",
    "                                              usecols=cols[i],\n",
    "                                              chunksize=50000,\n",
    "                                              low_memory=False)):\n",
    "            print(i)\n",
    "            if subset is None:\n",
    "                subset = chunk.copy()\n",
    "            else:\n",
    "                subset = pd.concat([subset, chunk])\n",
    "            del chunk\n",
    "            gc.collect()\n",
    "        if testdata is None:\n",
    "            testdata = subset.copy()\n",
    "        else:\n",
    "            testdata = pd.merge(testdata, subset.copy(), on=\"Id\")\n",
    "        del subset\n",
    "        gc.collect()\n",
    "        \n",
    "    traindata = traindata.merge(df_mindate, on='Id')\n",
    "    testdata = testdata.merge(df_mindate, on='Id')\n",
    "        \n",
    "    testdata['Response'] = 0  # Add Dummy Value\n",
    "    visibletraindata = traindata[::2]\n",
    "    blindtraindata = traindata[1::2]\n",
    "    print(blindtraindata.columns)\n",
    "    for i in range(2):\n",
    "        for col in cols[i][1:]:\n",
    "            print(col)\n",
    "            blindtraindata.loc[:, col] = LeaveOneOut(visibletraindata,\n",
    "                                                     blindtraindata,\n",
    "                                                     col, False).values\n",
    "            testdata.loc[:, col] = LeaveOneOut(visibletraindata,\n",
    "                                               testdata, col, False).values\n",
    "    del visibletraindata\n",
    "    gc.collect()\n",
    "    testdata.drop('Response', inplace=True, axis=1)\n",
    "    return blindtraindata, testdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef Train():\\n    train, test = GrabData()\\n    print(\\'Train:\\', train.shape)\\n    print(\\'Test\\', test.shape)\\n    features = list(train.columns)\\n    features.remove(\\'Response\\')\\n    features.remove(\\'Id\\')\\n    print(features)\\n    num_rounds = 50\\n    params = {}\\n    params[\\'objective\\'] = \"binary:logistic\"\\n    params[\\'eta\\'] = 0.021\\n    params[\\'max_depth\\'] = 7\\n    params[\\'colsample_bytree\\'] = 0.82\\n    params[\\'min_child_weight\\'] = 3\\n    params[\\'base_score\\'] = 0.005\\n    params[\\'silent\\'] = True\\n\\n    print(\\'Fitting\\')\\n    trainpredictions = None\\n    testpredictions = None\\n\\n    dvisibletrain =         xgb.DMatrix(train[features],\\n                    train.Response,\\n                    silent=True)\\n    dtest =         xgb.DMatrix(test[features],\\n                    silent=True)\\n\\n    folds = 1\\n    for i in range(folds):\\n        print(\\'Fold:\\', i)\\n        params[\\'seed\\'] = i\\n        watchlist = [(dvisibletrain, \\'train\\'), (dvisibletrain, \\'val\\')]\\n        clf = xgb.train(params, dvisibletrain,\\n                        num_boost_round=num_rounds,\\n                        evals=watchlist,\\n                        early_stopping_rounds=20,\\n                        feval=mcc_eval,\\n                        maximize=True\\n                        )\\n        limit = clf.best_iteration+1\\n        # limit = clf.best_ntree_limit\\n        predictions =             clf.predict(dvisibletrain, ntree_limit=limit)\\n\\n        best_proba, best_mcc, y_pred = eval_mcc(train.Response,\\n                                                predictions,\\n                                                True)\\n        print(\\'tree limit:\\', limit)\\n        print(\\'mcc:\\', best_mcc)\\n        print(matthews_corrcoef(train.Response,\\n                                y_pred))\\n        if(trainpredictions is None):\\n            trainpredictions = predictions\\n        else:\\n            trainpredictions += predictions\\n        predictions = clf.predict(dtest, ntree_limit=limit)\\n        if(testpredictions is None):\\n            testpredictions = predictions\\n        else:\\n            testpredictions += predictions\\n        imp = get_importance(clf, features)\\n        print(\\'Importance array: \\', imp)\\n\\n    best_proba, best_mcc, y_pred = eval_mcc(train.Response,\\n                                            trainpredictions/folds,\\n                                            True)\\n    print(matthews_corrcoef(train.Response,\\n                            y_pred))\\n\\n    submission = pd.DataFrame({\"Id\": train.Id,\\n                               \"Prediction\": trainpredictions/folds,\\n                               \"Response\": train.Response})\\n    submission[[\\'Id\\',\\n                \\'Prediction\\',\\n                \\'Response\\']].to_csv(\\'rawtrainxgbsubmission\\'+str(folds)+\\'.csv\\',\\n                                    index=False)\\n\\n    submission = pd.DataFrame({\"Id\": test.Id.values,\\n                               \"Response\": testpredictions/folds})\\n    submission[[\\'Id\\', \\'Response\\']].to_csv(\\'rawxgbsubmission\\'+str(folds)+\\'.csv\\',\\n                                          index=False)\\n    y_pred = (testpredictions/folds > .08).astype(int)\\n    submission = pd.DataFrame({\"Id\": test.Id.values,\\n                               \"Response\": y_pred})\\n    submission[[\\'Id\\', \\'Response\\']].to_csv(\\'xgbsubmission\\'+str(folds)+\\'.csv\\',\\n                                          index=False)\\n\\nif __name__ == \"__main__\":\\n    print(\\'Started\\')\\n    Train()\\n    print(\\'Finished\\')\\n    '"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def Train():\n",
    "    train, test = GrabData()\n",
    "    print('Train:', train.shape)\n",
    "    print('Test', test.shape)\n",
    "    features = list(train.columns)\n",
    "    features.remove('Response')\n",
    "    features.remove('Id')\n",
    "    print(features)\n",
    "    num_rounds = 50\n",
    "    params = {}\n",
    "    params['objective'] = \"binary:logistic\"\n",
    "    params['eta'] = 0.021\n",
    "    params['max_depth'] = 7\n",
    "    params['colsample_bytree'] = 0.82\n",
    "    params['min_child_weight'] = 3\n",
    "    params['base_score'] = 0.005\n",
    "    params['silent'] = True\n",
    "\n",
    "    print('Fitting')\n",
    "    trainpredictions = None\n",
    "    testpredictions = None\n",
    "\n",
    "    dvisibletrain = \\\n",
    "        xgb.DMatrix(train[features],\n",
    "                    train.Response,\n",
    "                    silent=True)\n",
    "    dtest = \\\n",
    "        xgb.DMatrix(test[features],\n",
    "                    silent=True)\n",
    "\n",
    "    folds = 1\n",
    "    for i in range(folds):\n",
    "        print('Fold:', i)\n",
    "        params['seed'] = i\n",
    "        watchlist = [(dvisibletrain, 'train'), (dvisibletrain, 'val')]\n",
    "        clf = xgb.train(params, dvisibletrain,\n",
    "                        num_boost_round=num_rounds,\n",
    "                        evals=watchlist,\n",
    "                        early_stopping_rounds=20,\n",
    "                        feval=mcc_eval,\n",
    "                        maximize=True\n",
    "                        )\n",
    "        limit = clf.best_iteration+1\n",
    "        # limit = clf.best_ntree_limit\n",
    "        predictions = \\\n",
    "            clf.predict(dvisibletrain, ntree_limit=limit)\n",
    "\n",
    "        best_proba, best_mcc, y_pred = eval_mcc(train.Response,\n",
    "                                                predictions,\n",
    "                                                True)\n",
    "        print('tree limit:', limit)\n",
    "        print('mcc:', best_mcc)\n",
    "        print(matthews_corrcoef(train.Response,\n",
    "                                y_pred))\n",
    "        if(trainpredictions is None):\n",
    "            trainpredictions = predictions\n",
    "        else:\n",
    "            trainpredictions += predictions\n",
    "        predictions = clf.predict(dtest, ntree_limit=limit)\n",
    "        if(testpredictions is None):\n",
    "            testpredictions = predictions\n",
    "        else:\n",
    "            testpredictions += predictions\n",
    "        imp = get_importance(clf, features)\n",
    "        print('Importance array: ', imp)\n",
    "\n",
    "    best_proba, best_mcc, y_pred = eval_mcc(train.Response,\n",
    "                                            trainpredictions/folds,\n",
    "                                            True)\n",
    "    print(matthews_corrcoef(train.Response,\n",
    "                            y_pred))\n",
    "\n",
    "    submission = pd.DataFrame({\"Id\": train.Id,\n",
    "                               \"Prediction\": trainpredictions/folds,\n",
    "                               \"Response\": train.Response})\n",
    "    submission[['Id',\n",
    "                'Prediction',\n",
    "                'Response']].to_csv('rawtrainxgbsubmission'+str(folds)+'.csv',\n",
    "                                    index=False)\n",
    "\n",
    "    submission = pd.DataFrame({\"Id\": test.Id.values,\n",
    "                               \"Response\": testpredictions/folds})\n",
    "    submission[['Id', 'Response']].to_csv('rawxgbsubmission'+str(folds)+'.csv',\n",
    "                                          index=False)\n",
    "    y_pred = (testpredictions/folds > .08).astype(int)\n",
    "    submission = pd.DataFrame({\"Id\": test.Id.values,\n",
    "                               \"Response\": y_pred})\n",
    "    submission[['Id', 'Response']].to_csv('xgbsubmission'+str(folds)+'.csv',\n",
    "                                          index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Started')\n",
    "    Train()\n",
    "    print('Finished')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def Train(train, test):\n",
    "def Train():\n",
    "    train, test = GrabData()\n",
    "    print('Train:', train.shape)\n",
    "    print('Test', test.shape)\n",
    "    features = list(train.columns)\n",
    "    features.remove('Response')\n",
    "    features.remove('Id')\n",
    "    print(features)\n",
    "    num_rounds = 50\n",
    "    params = {}\n",
    "    params['objective'] = \"binary:logistic\"\n",
    "    params['eta'] = 0.021\n",
    "    params['max_depth'] = 7\n",
    "    params['colsample_bytree'] = 0.82\n",
    "    params['min_child_weight'] = 3\n",
    "    params['base_score'] = 0.005\n",
    "    params['silent'] = True\n",
    "\n",
    "    print('Fitting')\n",
    "    trainpredictions = None\n",
    "    testpredictions = None\n",
    "\n",
    "    dvisibletrain = \\\n",
    "        xgb.DMatrix(train[features],\n",
    "                    train.Response,\n",
    "                    silent=True)\n",
    "    dtest = \\\n",
    "        xgb.DMatrix(test[features],\n",
    "                    silent=True)\n",
    "\n",
    "    folds = 1\n",
    "    for i in range(folds):\n",
    "        print('Fold:', i)\n",
    "        params['seed'] = i\n",
    "        watchlist = [(dvisibletrain, 'train'), (dvisibletrain, 'val')]\n",
    "        clf = xgb.train(params, dvisibletrain,\n",
    "                        num_boost_round=num_rounds,\n",
    "                        evals=watchlist,\n",
    "                        early_stopping_rounds=20,\n",
    "                        feval=mcc_eval,\n",
    "                        maximize=True\n",
    "                        )\n",
    "        limit = clf.best_iteration+1\n",
    "        # limit = clf.best_ntree_limit\n",
    "        predictions = \\\n",
    "            clf.predict(dvisibletrain, ntree_limit=limit)\n",
    "\n",
    "        best_proba, best_mcc, y_pred = eval_mcc(train.Response.values,\n",
    "                                                predictions,\n",
    "                                                True)\n",
    "        print('tree limit:', limit)\n",
    "        print('mcc:', best_mcc)\n",
    "        print(matthews_corrcoef(train.Response,\n",
    "                                y_pred))\n",
    "        if(trainpredictions is None):\n",
    "            trainpredictions = predictions\n",
    "        else:\n",
    "            trainpredictions += predictions\n",
    "        predictions = clf.predict(dtest, ntree_limit=limit)\n",
    "        if(testpredictions is None):\n",
    "            testpredictions = predictions\n",
    "        else:\n",
    "            testpredictions += predictions\n",
    "        imp = get_importance(clf, features)\n",
    "        print('Importance array: ', imp)\n",
    "\n",
    "    best_proba, best_mcc, y_pred = eval_mcc(train.Response.values,\n",
    "                                            trainpredictions/folds,\n",
    "                                            True)\n",
    "    print(matthews_corrcoef(train.Response,\n",
    "                            y_pred))\n",
    "\n",
    "    submission = pd.DataFrame({\"Id\": train.Id,\n",
    "                               \"Prediction\": trainpredictions/folds,\n",
    "                               \"Response\": train.Response})\n",
    "    submission[['Id',\n",
    "                'Prediction',\n",
    "                'Response']].to_csv('rawtrainxgbsubmission'+str(folds)+'.csv',\n",
    "                                    index=False)\n",
    "\n",
    "    submission = pd.DataFrame({\"Id\": test.Id.values,\n",
    "                               \"Response\": testpredictions/folds})\n",
    "    submission[['Id', 'Response']].to_csv('rawxgbsubmission'+str(folds)+'.csv',\n",
    "                                          index=False)\n",
    "    #y_pred = (testpredictions/folds > .08).astype(int)\n",
    "    y_pred = (testpredictions/folds > .08).astype(int)\n",
    "    submission = pd.DataFrame({\"Id\": test.Id.values,\n",
    "                               \"Response\": y_pred})\n",
    "    submission[['Id', 'Response']].to_csv('xgbsubmission'+str(folds)+'.csv',\n",
    "                                          index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Started')\n",
    "    Train()\n",
    "    print('Finished')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_categorical.csv\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "train_date.csv\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "train_numeric.csv\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "test_categorical.csv\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "test_date.csv\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "test_numeric.csv\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "Index(['Id', 'L1_S24_F1510', 'L1_S24_F1525', 'L1_S24_F1559', 'L1_S24_F1582',\n",
      "       'L1_S24_F1827', 'L3_S32_F3851', 'L3_S32_F3854', 'L0_S2_D34',\n",
      "       'L0_S3_D70', 'L0_S7_D137', 'L3_S29_D3474', 'L3_S30_D3496',\n",
      "       'L3_S30_D3501', 'L3_S30_D3506', 'L3_S30_D3511', 'L3_S30_D3516',\n",
      "       'L3_S32_D3852', 'L3_S33_D3856', 'L3_S34_D3875', 'L3_S35_D3886',\n",
      "       'L3_S49_D4208', 'L0_S0_F18', 'L0_S0_F20', 'L0_S2_F44', 'L0_S3_F72',\n",
      "       'L0_S4_F104', 'L0_S9_F160', 'L0_S10_F224', 'L0_S10_F264', 'L0_S15_F418',\n",
      "       'L1_S24_F1134', 'L1_S24_F1498', 'L1_S24_F1514', 'L1_S24_F1609',\n",
      "       'L1_S24_F1723', 'L1_S24_F1844', 'L1_S24_F1846', 'L1_S25_F2136',\n",
      "       'L2_S26_F3117', 'L3_S29_F3327', 'L3_S29_F3339', 'L3_S29_F3342',\n",
      "       'L3_S29_F3354', 'L3_S29_F3376', 'L3_S29_F3382', 'L3_S29_F3479',\n",
      "       'L3_S30_F3494', 'L3_S30_F3554', 'L3_S30_F3569', 'L3_S30_F3604',\n",
      "       'L3_S30_F3704', 'L3_S30_F3709', 'L3_S30_F3754', 'L3_S30_F3759',\n",
      "       'L3_S30_F3774', 'L3_S30_F3784', 'L3_S32_F3850', 'L3_S33_F3855',\n",
      "       'L3_S33_F3857', 'L3_S33_F3859', 'L3_S33_F3865', 'L3_S36_F3920',\n",
      "       'L3_S38_F3952', 'Response', 'mindate', 'maxdate', 'diff',\n",
      "       'mindate_id_diff', 'mindate_id_diff_reverse'],\n",
      "      dtype='object')\n",
      "L1_S24_F1559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L3_S32_F3851\n",
      "L1_S24_F1827\n",
      "L1_S24_F1582\n",
      "L3_S32_F3854\n",
      "L1_S24_F1510\n",
      "L1_S24_F1525\n",
      "L3_S30_D3496\n",
      "L3_S30_D3506\n",
      "L3_S30_D3501\n",
      "L3_S30_D3516\n",
      "L3_S30_D3511\n",
      "L0_S2_D34\n",
      "L0_S3_D70\n",
      "L0_S7_D137\n",
      "L3_S29_D3474\n",
      "L3_S32_D3852\n",
      "L3_S33_D3856\n",
      "L3_S34_D3875\n",
      "L3_S35_D3886\n",
      "L3_S49_D4208\n"
     ]
    }
   ],
   "source": [
    "train, test = GrabData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "Train: (591873, 70)\n",
      "Test (1183748, 69)\n",
      "['L1_S24_F1510', 'L1_S24_F1525', 'L1_S24_F1559', 'L1_S24_F1582', 'L1_S24_F1827', 'L3_S32_F3851', 'L3_S32_F3854', 'L0_S2_D34', 'L0_S3_D70', 'L0_S7_D137', 'L3_S29_D3474', 'L3_S30_D3496', 'L3_S30_D3501', 'L3_S30_D3506', 'L3_S30_D3511', 'L3_S30_D3516', 'L3_S32_D3852', 'L3_S33_D3856', 'L3_S34_D3875', 'L3_S35_D3886', 'L3_S49_D4208', 'L0_S0_F18', 'L0_S0_F20', 'L0_S2_F44', 'L0_S3_F72', 'L0_S4_F104', 'L0_S9_F160', 'L0_S10_F224', 'L0_S10_F264', 'L0_S15_F418', 'L1_S24_F1134', 'L1_S24_F1498', 'L1_S24_F1514', 'L1_S24_F1609', 'L1_S24_F1723', 'L1_S24_F1844', 'L1_S24_F1846', 'L1_S25_F2136', 'L2_S26_F3117', 'L3_S29_F3327', 'L3_S29_F3339', 'L3_S29_F3342', 'L3_S29_F3354', 'L3_S29_F3376', 'L3_S29_F3382', 'L3_S29_F3479', 'L3_S30_F3494', 'L3_S30_F3554', 'L3_S30_F3569', 'L3_S30_F3604', 'L3_S30_F3704', 'L3_S30_F3709', 'L3_S30_F3754', 'L3_S30_F3759', 'L3_S30_F3774', 'L3_S30_F3784', 'L3_S32_F3850', 'L3_S33_F3855', 'L3_S33_F3857', 'L3_S33_F3859', 'L3_S33_F3865', 'L3_S36_F3920', 'L3_S38_F3952', 'mindate', 'maxdate', 'diff', 'mindate_id_diff', 'mindate_id_diff_reverse']\n",
      "Fitting\n",
      "Fold: 0\n",
      "[0]\ttrain-MCC:0.296593\tval-MCC:0.296593\n",
      "Multiple eval metrics have been passed: 'val-MCC' will be used for early stopping.\n",
      "\n",
      "Will train until val-MCC hasn't improved in 20 rounds.\n",
      "[1]\ttrain-MCC:0.305727\tval-MCC:0.305727\n",
      "[2]\ttrain-MCC:0.340953\tval-MCC:0.340953\n",
      "[3]\ttrain-MCC:0.351807\tval-MCC:0.351807\n",
      "[4]\ttrain-MCC:0.360563\tval-MCC:0.360563\n",
      "[5]\ttrain-MCC:0.362428\tval-MCC:0.362428\n",
      "[6]\ttrain-MCC:0.364164\tval-MCC:0.364164\n",
      "[7]\ttrain-MCC:0.365259\tval-MCC:0.365259\n",
      "[8]\ttrain-MCC:0.365733\tval-MCC:0.365733\n",
      "[9]\ttrain-MCC:0.366408\tval-MCC:0.366408\n",
      "[10]\ttrain-MCC:0.366887\tval-MCC:0.366887\n",
      "[11]\ttrain-MCC:0.367131\tval-MCC:0.367131\n",
      "[12]\ttrain-MCC:0.367642\tval-MCC:0.367642\n",
      "[13]\ttrain-MCC:0.367688\tval-MCC:0.367688\n",
      "[14]\ttrain-MCC:0.367961\tval-MCC:0.367961\n",
      "[15]\ttrain-MCC:0.367603\tval-MCC:0.367603\n",
      "[16]\ttrain-MCC:0.368027\tval-MCC:0.368027\n",
      "[17]\ttrain-MCC:0.367814\tval-MCC:0.367814\n",
      "[18]\ttrain-MCC:0.369692\tval-MCC:0.369692\n",
      "[19]\ttrain-MCC:0.370887\tval-MCC:0.370887\n",
      "[20]\ttrain-MCC:0.372041\tval-MCC:0.372041\n",
      "[21]\ttrain-MCC:0.372919\tval-MCC:0.372919\n",
      "[22]\ttrain-MCC:0.374\tval-MCC:0.374\n",
      "[23]\ttrain-MCC:0.374272\tval-MCC:0.374272\n",
      "[24]\ttrain-MCC:0.373795\tval-MCC:0.373795\n",
      "[25]\ttrain-MCC:0.374864\tval-MCC:0.374864\n",
      "[26]\ttrain-MCC:0.375801\tval-MCC:0.375801\n",
      "[27]\ttrain-MCC:0.376176\tval-MCC:0.376176\n",
      "[28]\ttrain-MCC:0.376176\tval-MCC:0.376176\n",
      "[29]\ttrain-MCC:0.376458\tval-MCC:0.376458\n",
      "[30]\ttrain-MCC:0.37655\tval-MCC:0.37655\n",
      "[31]\ttrain-MCC:0.377298\tval-MCC:0.377298\n",
      "[32]\ttrain-MCC:0.377298\tval-MCC:0.377298\n",
      "[33]\ttrain-MCC:0.377391\tval-MCC:0.377391\n",
      "[34]\ttrain-MCC:0.377764\tval-MCC:0.377764\n",
      "[35]\ttrain-MCC:0.377391\tval-MCC:0.377391\n",
      "[36]\ttrain-MCC:0.377764\tval-MCC:0.377764\n",
      "[37]\ttrain-MCC:0.377484\tval-MCC:0.377484\n",
      "[38]\ttrain-MCC:0.377953\tval-MCC:0.377953\n",
      "[39]\ttrain-MCC:0.378055\tval-MCC:0.378055\n",
      "[40]\ttrain-MCC:0.378145\tval-MCC:0.378145\n",
      "[41]\ttrain-MCC:0.378137\tval-MCC:0.378137\n",
      "[42]\ttrain-MCC:0.378045\tval-MCC:0.378045\n",
      "[43]\ttrain-MCC:0.378251\tval-MCC:0.378251\n",
      "[44]\ttrain-MCC:0.378326\tval-MCC:0.378326\n",
      "[45]\ttrain-MCC:0.378326\tval-MCC:0.378326\n",
      "[46]\ttrain-MCC:0.378763\tval-MCC:0.378763\n",
      "[47]\ttrain-MCC:0.379396\tval-MCC:0.379396\n",
      "[48]\ttrain-MCC:0.379556\tval-MCC:0.379556\n",
      "[49]\ttrain-MCC:0.380521\tval-MCC:0.380521\n",
      "tree limit: 50\n",
      "mcc: 0.380520535886\n",
      "0.380520535886\n",
      "Importance array:  [('mindate', 203), ('maxdate', 191), ('mindate_id_diff_reverse', 119), ('mindate_id_diff', 119), ('diff', 114), ('L3_S33_F3857', 96), ('L3_S33_F3859', 96), ('L0_S0_F20', 93), ('L1_S24_F1846', 73), ('L3_S32_F3854', 73), ('L3_S32_F3850', 69), ('L3_S30_F3704', 67), ('L0_S4_F104', 62), ('L1_S24_F1844', 59), ('L3_S30_F3754', 56), ('L3_S36_F3920', 52), ('L3_S29_F3342', 52), ('L3_S30_F3759', 51), ('L0_S0_F18', 51), ('L3_S29_F3339', 46), ('L3_S29_F3382', 44), ('L3_S29_F3327', 42), ('L3_S33_F3865', 42), ('L3_S30_F3604', 39), ('L3_S38_F3952', 38), ('L1_S24_F1514', 38), ('L3_S30_F3784', 37), ('L3_S30_F3709', 35), ('L0_S2_F44', 35), ('L1_S24_F1723', 34), ('L3_S29_F3376', 33), ('L3_S30_F3569', 30), ('L1_S24_F1609', 29), ('L3_S30_F3554', 28), ('L1_S24_F1498', 26), ('L3_S30_F3494', 24), ('L2_S26_F3117', 24), ('L0_S9_F160', 23), ('L3_S29_F3479', 23), ('L3_S33_F3855', 21), ('L0_S3_F72', 21), ('L3_S30_F3774', 20), ('L3_S29_F3354', 15), ('L1_S25_F2136', 11), ('L0_S15_F418', 5), ('L0_S10_F224', 1)]\n",
      "0.380520535886\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print('Started')\n",
    "    Train(train, test)\n",
    "    print('Finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('maxdate', 177),\n",
       " ('mindate', 173),\n",
       " ('diff', 126),\n",
       " ('mindate_id_diff_reverse', 114),\n",
       " ('mindate_id_diff', 111),\n",
       " ('L3_S33_F3859', 97),\n",
       " ('L3_S33_F3857', 72),\n",
       " ('L3_S30_F3704', 72),\n",
       " ('L3_S32_F3854', 71),\n",
       " ('L3_S32_F3850', 71),\n",
       " ('L0_S0_F20', 68),\n",
       " ('L0_S4_F104', 67),\n",
       " ('L3_S30_F3754', 62),\n",
       " ('L3_S29_F3327', 57),\n",
       " ('L3_S29_F3339', 50),\n",
       " ('L1_S24_F1846', 50),\n",
       " ('L3_S30_F3759', 50),\n",
       " ('L3_S30_F3604', 50),\n",
       " ('L0_S0_F18', 48),\n",
       " ('L3_S29_F3382', 46),\n",
       " ('L3_S30_F3709', 44),\n",
       " ('L3_S29_F3342', 43),\n",
       " ('L3_S36_F3920', 43),\n",
       " ('L1_S24_F1514', 38),\n",
       " ('L3_S33_F3865', 38),\n",
       " ('L3_S38_F3952', 36),\n",
       " ('L0_S2_F44', 35),\n",
       " ('L3_S30_F3554', 34),\n",
       " ('L1_S24_F1844', 31),\n",
       " ('L3_S33_F3855', 30),\n",
       " ('L0_S9_F160', 27),\n",
       " ('L1_S24_F1723', 26),\n",
       " ('L3_S30_F3569', 25),\n",
       " ('L0_S3_F72', 24),\n",
       " ('L3_S29_F3376', 24),\n",
       " ('L1_S24_F1498', 23),\n",
       " ('L3_S29_F3354', 22),\n",
       " ('L3_S29_F3479', 22),\n",
       " ('L3_S30_F3774', 22),\n",
       " ('L1_S24_F1609', 22),\n",
       " ('L3_S30_F3784', 21),\n",
       " ('L2_S26_F3117', 21),\n",
       " ('L3_S30_F3494', 20),\n",
       " ('L0_S1_F28', 18),\n",
       " ('L3_S30_F3534', 18),\n",
       " ('L1_S24_F1604', 17),\n",
       " ('L3_S30_F3794', 14),\n",
       " ('L3_S29_F3373', 13),\n",
       " ('L1_S24_F1632', 13),\n",
       " ('L3_S29_F3315', 13),\n",
       " ('L1_S24_F1565', 13),\n",
       " ('L3_S29_F3321', 12),\n",
       " ('L3_S30_F3509', 12),\n",
       " ('L1_S24_F1783', 12),\n",
       " ('L1_S24_F1695', 12),\n",
       " ('L3_S29_F3407', 11),\n",
       " ('L0_S13_F354', 10),\n",
       " ('L0_S9_F175', 10),\n",
       " ('L0_S2_F60', 7),\n",
       " ('L1_S25_F2126', 7),\n",
       " ('L0_S11_F290', 7),\n",
       " ('L3_S29_F3461', 6),\n",
       " ('L0_S15_F406', 5),\n",
       " ('L0_S10_F249', 4),\n",
       " ('L1_S25_F2176', 4),\n",
       " ('L1_S24_F897', 2),\n",
       " ('L0_S16_F426', 1))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Importance_array = ('maxdate', 177), ('mindate', 173), ('diff', 126), ('mindate_id_diff_reverse', 114), ('mindate_id_diff', 111), ('L3_S33_F3859', 97), ('L3_S33_F3857', 72), ('L3_S30_F3704', 72), ('L3_S32_F3854', 71), ('L3_S32_F3850', 71), ('L0_S0_F20', 68), ('L0_S4_F104', 67), ('L3_S30_F3754', 62), ('L3_S29_F3327', 57), ('L3_S29_F3339', 50), ('L1_S24_F1846', 50), ('L3_S30_F3759', 50), ('L3_S30_F3604', 50), ('L0_S0_F18', 48), ('L3_S29_F3382', 46), ('L3_S30_F3709', 44), ('L3_S29_F3342', 43), ('L3_S36_F3920', 43), ('L1_S24_F1514', 38), ('L3_S33_F3865', 38), ('L3_S38_F3952', 36), ('L0_S2_F44', 35), ('L3_S30_F3554', 34), ('L1_S24_F1844', 31), ('L3_S33_F3855', 30), ('L0_S9_F160', 27), ('L1_S24_F1723', 26), ('L3_S30_F3569', 25), ('L0_S3_F72', 24), ('L3_S29_F3376', 24), ('L1_S24_F1498', 23), ('L3_S29_F3354', 22), ('L3_S29_F3479', 22), ('L3_S30_F3774', 22), ('L1_S24_F1609', 22), ('L3_S30_F3784', 21), ('L2_S26_F3117', 21), ('L3_S30_F3494', 20), ('L0_S1_F28', 18), ('L3_S30_F3534', 18), ('L1_S24_F1604', 17), ('L3_S30_F3794', 14), ('L3_S29_F3373', 13), ('L1_S24_F1632', 13), ('L3_S29_F3315', 13), ('L1_S24_F1565', 13), ('L3_S29_F3321', 12), ('L3_S30_F3509', 12), ('L1_S24_F1783', 12), ('L1_S24_F1695', 12), ('L3_S29_F3407', 11), ('L0_S13_F354', 10), ('L0_S9_F175', 10), ('L0_S2_F60', 7), ('L1_S25_F2126', 7), ('L0_S11_F290', 7), ('L3_S29_F3461', 6), ('L0_S15_F406', 5), ('L0_S10_F249', 4), ('L1_S25_F2176', 4), ('L1_S24_F897', 2), ('L0_S16_F426', 1)\n",
    "Importance_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('mindate', 203),\n",
       " ('maxdate', 191),\n",
       " ('mindate_id_diff_reverse', 119),\n",
       " ('mindate_id_diff', 119),\n",
       " ('diff', 114),\n",
       " ('L3_S33_F3857', 96),\n",
       " ('L3_S33_F3859', 96),\n",
       " ('L0_S0_F20', 93),\n",
       " ('L1_S24_F1846', 73),\n",
       " ('L3_S32_F3854', 73),\n",
       " ('L3_S32_F3850', 69),\n",
       " ('L3_S30_F3704', 67),\n",
       " ('L0_S4_F104', 62),\n",
       " ('L1_S24_F1844', 59),\n",
       " ('L3_S30_F3754', 56),\n",
       " ('L3_S36_F3920', 52),\n",
       " ('L3_S29_F3342', 52),\n",
       " ('L3_S30_F3759', 51),\n",
       " ('L0_S0_F18', 51),\n",
       " ('L3_S29_F3339', 46),\n",
       " ('L3_S29_F3382', 44),\n",
       " ('L3_S29_F3327', 42),\n",
       " ('L3_S33_F3865', 42),\n",
       " ('L3_S30_F3604', 39),\n",
       " ('L3_S38_F3952', 38),\n",
       " ('L1_S24_F1514', 38),\n",
       " ('L3_S30_F3784', 37),\n",
       " ('L3_S30_F3709', 35),\n",
       " ('L0_S2_F44', 35),\n",
       " ('L1_S24_F1723', 34),\n",
       " ('L3_S29_F3376', 33),\n",
       " ('L3_S30_F3569', 30),\n",
       " ('L1_S24_F1609', 29),\n",
       " ('L3_S30_F3554', 28),\n",
       " ('L1_S24_F1498', 26),\n",
       " ('L3_S30_F3494', 24),\n",
       " ('L2_S26_F3117', 24),\n",
       " ('L0_S9_F160', 23),\n",
       " ('L3_S29_F3479', 23),\n",
       " ('L3_S33_F3855', 21),\n",
       " ('L0_S3_F72', 21),\n",
       " ('L3_S30_F3774', 20),\n",
       " ('L3_S29_F3354', 15),\n",
       " ('L1_S25_F2136', 11),\n",
       " ('L0_S15_F418', 5),\n",
       " ('L0_S10_F224', 1))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Importance_array_2 = ('mindate', 203), ('maxdate', 191), ('mindate_id_diff_reverse', 119), ('mindate_id_diff', 119), ('diff', 114), ('L3_S33_F3857', 96), ('L3_S33_F3859', 96), ('L0_S0_F20', 93), ('L1_S24_F1846', 73), ('L3_S32_F3854', 73), ('L3_S32_F3850', 69), ('L3_S30_F3704', 67), ('L0_S4_F104', 62), ('L1_S24_F1844', 59), ('L3_S30_F3754', 56), ('L3_S36_F3920', 52), ('L3_S29_F3342', 52), ('L3_S30_F3759', 51), ('L0_S0_F18', 51), ('L3_S29_F3339', 46), ('L3_S29_F3382', 44), ('L3_S29_F3327', 42), ('L3_S33_F3865', 42), ('L3_S30_F3604', 39), ('L3_S38_F3952', 38), ('L1_S24_F1514', 38), ('L3_S30_F3784', 37), ('L3_S30_F3709', 35), ('L0_S2_F44', 35), ('L1_S24_F1723', 34), ('L3_S29_F3376', 33), ('L3_S30_F3569', 30), ('L1_S24_F1609', 29), ('L3_S30_F3554', 28), ('L1_S24_F1498', 26), ('L3_S30_F3494', 24), ('L2_S26_F3117', 24), ('L0_S9_F160', 23), ('L3_S29_F3479', 23), ('L3_S33_F3855', 21), ('L0_S3_F72', 21), ('L3_S30_F3774', 20), ('L3_S29_F3354', 15), ('L1_S25_F2136', 11), ('L0_S15_F418', 5), ('L0_S10_F224', 1)\n",
    "Importance_array_2"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
